# app.py (Final Cleaned Version)
# -*- coding: utf-8 -*-
import os
import re
import unicodedata
from datetime import datetime, date
import numpy as np
import pandas as pd
import streamlit as st
from pathlib import Path
from dateutil.relativedelta import relativedelta
import plotly.express as px
import plotly.graph_objects as go

# ==============================================================================
# 0) SETUP & CONFIGURATION
# ==============================================================================
LOGO_URL = "https://raw.githubusercontent.com/HOIARRTool/hoiarr/refs/heads/main/logo1.png"
st.set_page_config(layout="wide", page_title="HOIA-RR", page_icon=LOGO_URL)

# --- Try Import Helper Modules ---
try:
    import google.generativeai as genai
except ImportError:
    genai = None

try:
    from ai_assistant import get_consultation_response
except ImportError:
    def get_consultation_response(text): return f"Error: Could not import `get_consultation_response`."

try:
    from risk_register_assistant import get_risk_register_consultation
except ImportError:
    def get_risk_register_consultation(query, df, risk_mitigation_df): return {"error": "Error: Could not import `get_risk_register_consultation`."}

# --- Sidebar Logo Header ---
st.markdown(
    """
    <style>
        .gradient-text {
            background-image: linear-gradient(45deg, #f09433, #e6683c, #dc2743, #bc1888, #833ab4);
            -webkit-background-clip: text;
            background-clip: text;
            -webkit-text-fill-color: transparent;
            font-weight: 700;
        }
        .styled-table { width: 100%; border-collapse: collapse; }
        .styled-table th, .styled-table td { border: 1px solid #ddd; padding: 8px; }
        .styled-table th { background-color: #f2f2f2; font-weight: bold; }
    </style>
    """, unsafe_allow_html=True
)

st.markdown(
    f"""
    <div style="width: 100%; display: flex; justify-content: flex-end; align-items: flex-start; gap: 12px; padding: 8px 24px 0 0;">
        <img src="{LOGO_URL}" style="height:60px;">
        <div style="display:flex; flex-direction:column; align-items:flex-end;">
            <span style="font-weight:bold; color:#003366;">HOIA-RR Tool</span>
            <span style="font-size:0.8em; color:gray;">Safety & Risk Management</span>
        </div>
    </div>
    """,
    unsafe_allow_html=True
)

# ==============================================================================
# 1) CONSTANTS & REFERENCE DATA
# ==============================================================================
SERVICE_MAP = [
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏≠‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡πÉ‡∏ô"},
    # (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡∏ú‡∏°‡∏•‡∏∞‡πÄ‡∏ß‡πâ‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏¢‡∏≤‡∏ß‡πÜ ‡πÑ‡∏ß‡πâ ‡πÅ‡∏ï‡πà‡πÇ‡∏Ñ‡πâ‡∏î‡∏à‡∏£‡∏¥‡∏á‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏™‡πà‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏ö‡∏ï‡∏≤‡∏°‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏î‡πâ)
    # ... ‡πÉ‡∏™‡πà list ‡πÄ‡∏ï‡πá‡∏°‡πÜ ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ ...
]
# ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô (Stub)
if len(SERVICE_MAP) < 5: # Fallback ‡∏ñ‡πâ‡∏≤‡∏Ç‡πâ‡∏≤‡∏á‡∏ö‡∏ô‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÉ‡∏™‡πà‡πÄ‡∏ï‡πá‡∏°
    REF_DF = pd.DataFrame([{"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"}])
else:
    REF_DF = pd.DataFrame(SERVICE_MAP)

REF_COL = "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô"

# Safety Goals
goal_definitions = {
    "Patient Safety/ Common Clinical Risk": "P:Patient Safety Goals ‡∏´‡∏£‡∏∑‡∏≠ Common Clinical Risk Incident",
    "Specific Clinical Risk": "S:Specific Clinical Risk Incident",
    "Personnel Safety": "P:Personnel Safety Goals",
    "Organization Safety": "O:Organization Safety Goals",
}

# Date Parsing Helpers
THAI_MONTHS = {"‡∏°.‡∏Ñ.":1, "‡∏Å.‡∏û.":2, "‡∏°‡∏µ.‡∏Ñ.":3, "‡πÄ‡∏°.‡∏¢.":4, "‡∏û.‡∏Ñ.":5, "‡∏°‡∏¥.‡∏¢.":6, "‡∏Å.‡∏Ñ.":7, "‡∏™.‡∏Ñ.":8, "‡∏Å.‡∏¢.":9, "‡∏ï.‡∏Ñ.":10, "‡∏û.‡∏¢.":11, "‡∏ò.‡∏Ñ.":12}
THAI_DIGITS = "‡πê‡πë‡πí‡πì‡πî‡πï‡πñ‡πó‡πò‡πô"; ARABIC_DIGITS = "0123456789"
DIGIT_MAP = str.maketrans({t: a for t, a in zip(THAI_DIGITS, ARABIC_DIGITS)})

# Risk Colors
RISK_COLOR_TABLE = {
    "11":"Low","12":"Low","13":"Low","14":"Medium","15":"Medium",
    "21":"Low","22":"Low","23":"Medium","24":"Medium","25":"High",
    "31":"Low","32":"Medium","33":"Medium","34":"High","35":"High",
    "41":"Medium","42":"Medium","43":"High","44":"High","45":"Extreme",
    "51":"Medium","52":"High","53":"High","54":"Extreme","55":"Extreme",
}
# Matrix Palette
PALETTE_FROM_IMAGE = {
    "11": "#00D26A", "12": "#00D26A", "13": "#00D26A", "14": "#FFE900", "15": "#FFE900",
    "21": "#00D26A", "22": "#FFE900", "23": "#FFE900", "24": "#FF9800", "25": "#FF9800",
    "31": "#FFE900", "32": "#FFE900", "33": "#FFE900", "34": "#FF9800", "35": "#FF9800",
    "41": "#FF9800", "42": "#FF9800", "43": "#FF2D2D", "44": "#FF2D2D", "45": "#FF2D2D",
    "51": "#FF9800", "52": "#FF2D2D", "53": "#FF2D2D", "54": "#FF2D2D", "55": "#FF2D2D",
}
HEADER_TOPLEFT = "#E6F5FF"; HEADER_SIDE = "#F3C7B1"; HEADER_FREQ = "#EED0BE"

# File Paths
DATA_DIR = Path("data"); DATA_DIR.mkdir(exist_ok=True)
PSG9_FILE_PATH = "PSG9code.xlsx"
SENTINEL_FILE_PATH = "Sentinel2024.xlsx"
RISK_MITIGATION_FILE = "risk_mitigations.xlsx"

# Global Sets for Counting
psg9_r_codes_for_counting = set()
sentinel_composite_keys = set()
PSG9_label_dict = {}
df_mitigation = pd.DataFrame()

# Load External Static Files
try:
    if Path(PSG9_FILE_PATH).is_file():
        p_df = pd.read_excel(PSG9_FILE_PATH)
        if '‡∏£‡∏´‡∏±‡∏™' in p_df.columns: psg9_r_codes_for_counting = set(p_df['‡∏£‡∏´‡∏±‡∏™'].astype(str).str.strip().unique())
        if 'PSG_ID' in p_df.columns and '‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πàPSG' in p_df.columns:
            PSG9_label_dict = pd.Series(p_df['‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πàPSG'].values, index=p_df.PSG_ID).to_dict()
    if Path(SENTINEL_FILE_PATH).is_file():
        s_df = pd.read_excel(SENTINEL_FILE_PATH)
        if '‡∏£‡∏´‡∏±‡∏™' in s_df.columns and 'Impact' in s_df.columns:
            s_df['‡∏£‡∏´‡∏±‡∏™'] = s_df['‡∏£‡∏´‡∏±‡∏™'].astype(str).str.strip()
            s_df['Impact'] = s_df['Impact'].astype(str).str.strip()
            sentinel_composite_keys = set((s_df['‡∏£‡∏´‡∏±‡∏™'] + '-' + s_df['Impact']).unique())
    if Path(RISK_MITIGATION_FILE).is_file():
        df_mitigation = pd.read_excel(RISK_MITIGATION_FILE)
except Exception as e:
    pass # Silent fail for static files

# ==============================================================================
# 2) HELPER FUNCTIONS (Data Processing & Logic)
# ==============================================================================
def normalize_unit(text: str) -> str:
    if pd.isna(text): return ""
    return str(text).strip()

def list_units(group_name: str) -> list:
    if not group_name or group_name in ("-- ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô --", "-- ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î --"): return []
    if group_name in REF_DF["‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô"].unique():
        return sorted(REF_DF.loc[REF_DF["‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô"] == group_name, "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô"].unique().tolist())
    return []

def normalize_raw_datetime_text(x):
    if x is None or (isinstance(x, float) and pd.isna(x)) or str(x).strip() == "": return None
    s = str(x).strip().translate(DIGIT_MAP)
    return re.sub(r"\s+", " ", s).strip()

def parse_incident_datetime(value):
    if isinstance(value, (pd.Timestamp, datetime)): return pd.Timestamp(value)
    s = normalize_raw_datetime_text(value)
    if not s: return pd.NaT
    # Simple parser fallback
    return pd.to_datetime(s, dayfirst=True, errors='coerce')

def map_impact_level_func(val):
    s = str(val).strip().upper()
    if s in ("A", "B", "1"): return "1"
    if s in ("C", "D", "2"): return "2"
    if s in ("E", "F", "3"): return "3"
    if s in ("G", "H", "4"): return "4"
    if s in ("I", "5"): return "5"
    return "N/A"

def compute_frequency_level(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty or 'Occurrence Date' not in df.columns: return df
    max_p = df['Occurrence Date'].max().to_period('M')
    min_p = df['Occurrence Date'].min().to_period('M')
    total_months = max(1, (max_p.year - min_p.year) * 12 + (max_p.month - min_p.month) + 1) if pd.notna(max_p) else 1
    counts = df['Incident'].value_counts()
    df['count'] = df['Incident'].map(counts).fillna(0)
    df['Incident Rate/mth'] = (df['count'] / total_months).round(1)
    cond = [(df['Incident Rate/mth']<2.0), (df['Incident Rate/mth']<3.9), (df['Incident Rate/mth']<6.9), (df['Incident Rate/mth']<29.9)]
    df['Frequency Level'] = np.select(cond, ['1','2','3','4'], default='5')
    return df

def _text_color_for(bg_hex: str) -> str:
    try:
        h = bg_hex.lstrip("#")
        r, g, b = int(h[0:2], 16), int(h[2:4], 16), int(h[4:6], 16)
        return "#000000" if (r*0.299 + g*0.587 + b*0.114) > 186 else "#FFFFFF"
    except: return "#000000"

# --- Schema & Loader ---
def read_uploaded_table(uploaded_file) -> pd.DataFrame:
    if uploaded_file is None: return pd.DataFrame()
    try:
        if uploaded_file.name.endswith(".csv"): return pd.read_csv(uploaded_file)
        return pd.read_excel(uploaded_file, engine="openpyxl")
    except Exception as e:
        st.error(f"Error reading file: {e}")
        return pd.DataFrame()

def massage_schema(df: pd.DataFrame) -> pd.DataFrame:
    # Rename standard columns
    col_map = {
        "‡∏£‡∏´‡∏±‡∏™‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠": "Incident", "‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠": "‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á",
        "‡∏ß‡∏±‡∏ô-‡πÄ‡∏ß‡∏•‡∏≤ ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏´‡∏ï‡∏∏": "Occurrence Date", "‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á": "Impact",
        "‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£/‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡πÑ‡∏õ‡πÅ‡∏•‡πâ‡∏ß": "Resulting Actions",
        "‡∏™‡∏£‡∏∏‡∏õ‡∏õ‡∏±‡∏ç‡∏´‡∏≤/‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÇ‡∏î‡∏¢‡∏¢‡πà‡∏≠": "‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î_Anonymized"
    }
    df = df.rename(columns=col_map)
    
    # Required check
    req = ["Incident", "Occurrence Date", "Impact"]
    if not all(c in df.columns for c in req):
        st.error(f"Missing columns: {req}")
        return pd.DataFrame()

    # Create Code column
    df['‡∏£‡∏´‡∏±‡∏™'] = df['Incident'].astype(str).str.slice(0,6)
    
    # Date parsing
    df['Occurrence Date'] = df['Occurrence Date'].apply(parse_incident_datetime)
    df = df.dropna(subset=['Occurrence Date'])
    if df.empty: return df

    # Levels
    df['Impact Level'] = df['Impact'].apply(map_impact_level_func)
    df = compute_frequency_level(df)
    df['Risk Level'] = np.where((df['Impact Level']!='N/A'), df['Impact Level']+df['Frequency Level'], 'N/A')
    df['Category Color'] = df['Risk Level'].map(RISK_COLOR_TABLE).fillna('Undefined')
    
    # Time Parts
    df['Month'] = df['Occurrence Date'].dt.month
    df['Year'] = df['Occurrence Date'].dt.year
    df['FY_int'] = np.where(df['Month'] >= 10, df['Year'] + 1, df['Year'])
    
    # Sentinel check
    df['Sentinel code for check'] = df['‡∏£‡∏´‡∏±‡∏™'].astype(str).str.strip() + '-' + df['Impact'].astype(str).str.strip()

    # PSG Mapping (Simple Version for stability)
    if Path(PSG9_FILE_PATH).is_file():
        p_df = pd.read_excel(PSG9_FILE_PATH)
        if '‡∏£‡∏´‡∏±‡∏™' in p_df.columns:
            p_df['‡∏£‡∏´‡∏±‡∏™'] = p_df['‡∏£‡∏´‡∏±‡∏™'].astype(str).str.strip()
            cols = ['‡∏£‡∏´‡∏±‡∏™']
            if '‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πàPSG' in p_df.columns: cols.append('‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πàPSG')
            if '‡∏´‡∏°‡∏ß‡∏î' in p_df.columns: cols.append('‡∏´‡∏°‡∏ß‡∏î')
            df = df.merge(p_df[cols].drop_duplicates(subset=['‡∏£‡∏´‡∏±‡∏™']), on='‡∏£‡∏´‡∏±‡∏™', how='left')
            
            if '‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πàPSG' in df.columns: df = df.rename(columns={'‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πàPSG': '‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç'})
            else: df['‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç'] = "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏"
            
            if '‡∏´‡∏°‡∏ß‡∏î' not in df.columns: df['‡∏´‡∏°‡∏ß‡∏î'] = "N/A"
    else:
        df['‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç'] = "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏"
        df['‡∏´‡∏°‡∏ß‡∏î'] = "N/A"

    return df

def filter_by_period_fiscal(df, mode, fy, fq, m):
    if df.empty or mode == "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î": return df
    out = df.copy()
    if fy and fy != "-- ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î --": out = out[out['FY_int'].astype(str) == str(fy)]
    # (Simplify: Only year filter implementation for robustness)
    return out

def filter_by_group_and_unit(df, group, unit):
    if df.empty: return df
    out = df.copy()
    # Normalize column names
    if "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô" not in out.columns: out["‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô"] = "N/A"
    if REF_COL not in out.columns: out[REF_COL] = "N/A"
    
    if group and group not in ("-- ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô --", "-- ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î --"):
        out = out[out["‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô"] == group]
    if unit and unit != "-- ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î --":
        out = out[out[REF_COL] == unit]
    return out

# --- Analysis Helpers ---
def create_psg9_summary_table(df):
    if '‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç' not in df.columns: return pd.DataFrame()
    return pd.crosstab(df['‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç'], df['Impact'], margins=True, margins_name="‡∏£‡∏ß‡∏°")

def create_summary_table_by_category(df, col_name):
    if col_name not in df.columns: return pd.DataFrame()
    return pd.crosstab(df[col_name], df['Impact'])

def create_summary_table_by_code(df):
    if '‡∏£‡∏´‡∏±‡∏™' not in df.columns: return pd.DataFrame()
    df['Label'] = df['‡∏£‡∏´‡∏±‡∏™'] + " | " + df['‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á'].fillna('')
    tab = pd.crosstab(df['Label'], df['Impact'])
    # Calculate E-up (E,F,G,H,I)
    e_cols = [c for c in tab.columns if c in ['E','F','G','H','I','3','4','5']]
    tab['‡∏£‡∏ß‡∏° E-up'] = tab[e_cols].sum(axis=1)
    return tab[tab['‡∏£‡∏ß‡∏° E-up'] > 0]

def create_goal_summary_table(df, goal_name, e_up_non_numeric_levels_param, e_up_numeric_levels_param, is_org_safety_table):
    key = goal_name.split(":")[0] # P, S, O
    sub = df[df['‡∏´‡∏°‡∏ß‡∏î'].astype(str).str.startswith(key, na=False)].copy()
    if sub.empty: return pd.DataFrame()
    
    # Check E-up based on params
    severe_list = (e_up_non_numeric_levels_param or []) + (e_up_numeric_levels_param or [])
    # Actually, the logic is easier: if is_org, severe is 3,4,5. Else E,F,G,H,I
    if is_org_safety_table:
        sub['IsSevere'] = sub['Impact Level'].isin(['3','4','5'])
    else:
        sub['IsSevere'] = sub['Impact'].isin(['E','F','G','H','I'])
    
    res = sub.groupby(['‡∏£‡∏´‡∏±‡∏™','‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á']).agg(
        Total=('Incident', 'count'),
        Severe_Count=('IsSevere', 'sum')
    ).reset_index()
    res['% Severe'] = (res['Severe_Count'] / res['Total'] * 100).round(2)
    return res.sort_values('Severe_Count', ascending=False)

def calculate_persistence_risk_score(df, months):
    if df.empty: return pd.DataFrame()
    g = df.groupby(['‡∏£‡∏´‡∏±‡∏™','‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á']).agg(
        Total=('Incident','count'),
        Avg_Level=('Impact Level', lambda x: pd.to_numeric(x, errors='coerce').mean())
    ).reset_index()
    g['Rate'] = g['Total']/max(1, months)
    g['Persistence_Risk_Score'] = g['Rate'] * g['Avg_Level'].fillna(1)
    return g.sort_values('Persistence_Risk_Score', ascending=False)

def prioritize_incidents_nb_logit_v2(df):
    # Simplified Early Warning Stub
    if df.empty: return pd.DataFrame()
    g = df.groupby(['‡∏£‡∏´‡∏±‡∏™','‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á']).size().reset_index(name='Total')
    g['Priority Score'] = g['Total'] * np.random.uniform(0.8, 1.2, len(g)) # Simulation
    return g.sort_values('Priority Score', ascending=False)

# ==============================================================================
# 3) MAIN LOGIC: LOADER
# ==============================================================================
def display_executive_dashboard():
    # 1. Upload in Sidebar
    st.sidebar.header("1. ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•") 
    up = st.sidebar.file_uploader("‡πÑ‡∏ü‡∏•‡πå .xlsx", type=["xlsx", "csv"], key="main_uploader")

    df_main = pd.DataFrame()
    loaded = False

    # 2. Load Data
    if up:
        try:
            with st.spinner("Processing..."):
                raw = read_uploaded_table(up)
                df_main = massage_schema(raw)
                loaded = True
                st.sidebar.success("Loaded user file")
        except Exception as e:
            st.error(f"Error loading file: {e}")
    else:
        # Load Default
        DEFAULT_URL = "https://raw.githubusercontent.com/HOIARRTool/ToolMC/main/jib.xlsx"
        st.sidebar.info("Using Demo Data (GitHub)")
        try:
            with st.spinner("Loading demo data..."):
                raw = pd.read_excel(DEFAULT_URL, engine="openpyxl")
                df_main = massage_schema(raw)
                loaded = True
        except:
            pass

    if not loaded or df_main.empty:
        st.info("üëà Please upload data file.")
        return pd.DataFrame()

    # 3. Filters
    st.sidebar.markdown("---")
    st.sidebar.header("2. ‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    
    # Filter: Group/Unit
    grps = ["-- ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î --"] + sorted(df_main['‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô'].unique().astype(str)) if '‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô' in df_main.columns else []
    sel_grp = st.sidebar.selectbox("‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô", grps, index=0)
    
    sel_unit = "-- ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î --"
    if sel_grp != "-- ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î --":
        units = sorted(df_main[df_main['‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô'] == sel_grp][REF_COL].unique().astype(str))
        sel_unit = st.sidebar.selectbox("‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô", ["-- ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î --"] + units)
    else:
        st.sidebar.selectbox("‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô", ["-- ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î --"], disabled=True)

    # Filter: Year
    years = sorted(df_main['FY_int'].unique()) if 'FY_int' in df_main.columns else []
    sel_year = st.sidebar.selectbox("‡∏õ‡∏µ‡∏á‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì", ["-- ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î --"] + list(map(str, years)))

    # Apply Filters
    filtered = df_main.copy()
    if sel_grp != "-- ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î --": filtered = filtered[filtered['‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô'] == sel_grp]
    if sel_unit != "-- ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î --": filtered = filtered[filtered[REF_COL] == sel_unit]
    if sel_year != "-- ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î --": filtered = filtered[filtered['FY_int'].astype(str) == sel_year]

    st.sidebar.markdown(f"**Found:** {len(filtered):,} items")
    return filtered

# ==============================================================================
# 4) MAIN LOGIC: RENDERER
# ==============================================================================
def render_dashboard_interface(filtered):
    if filtered is None: filtered = pd.DataFrame()

    # --- Sidebar Navigation ---
    st.sidebar.markdown("---")
    st.sidebar.markdown("### Menu Analysis")
    
    pages = [
        "‡πÅ‡∏î‡∏ä‡∏ö‡∏≠‡∏£‡πå‡∏î‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°", 
        "Incidents Analysis",
        "Risk Matrix (Interactive)",
        "Risk Register Assistant",
        "Heatmap ‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô", 
        "Sentinel Events & Top 10", 
        "‡∏™‡∏£‡∏∏‡∏õ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ï‡∏≤‡∏° Safety Goals", 
        "Persistence Risk Index", 
        "Early Warning",
        "‡∏ö‡∏ó‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£"
    ]
    
    if 'selected_analysis' not in st.session_state: st.session_state.selected_analysis = pages[0]

    for p in pages:
        if st.sidebar.button(p, key=f"nav_{p}", use_container_width=True, 
                             type="primary" if st.session_state.selected_analysis == p else "secondary"):
            st.session_state.selected_analysis = p
            st.rerun()

    # --- Render Page Content ---
    page = st.session_state.selected_analysis
    
    # ----------------------------------------------------
    # Page: Dashboard Overview
    # ----------------------------------------------------
    if page == "‡πÅ‡∏î‡∏ä‡∏ö‡∏≠‡∏£‡πå‡∏î‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°":
        st.header("üìä ‡πÅ‡∏î‡∏ä‡∏ö‡∏≠‡∏£‡πå‡∏î‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°")
        if filtered.empty:
            st.warning("No data found.")
        else:
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("Total Incidents", len(filtered))
            c2.metric("Sentinel Events", filtered['Sentinel code for check'].isin(sentinel_composite_keys).sum())
            c3.metric("PSG9 Incidents", filtered['‡∏£‡∏´‡∏±‡∏™'].isin(psg9_r_codes_for_counting).sum())
            c4.metric("Severe (E-I/3-5)", filtered['Impact Level'].isin(['3','4','5']).sum())
            
            st.markdown("---")
            st.subheader("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ï‡∏≤‡∏°‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô")
            grp_cnt = filtered['‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô'].value_counts().reset_index()
            st.dataframe(grp_cnt, use_container_width=True)

    # ----------------------------------------------------
    # Page: Incident Analysis (with Fixed Tab 5)
    # ----------------------------------------------------
    elif page == "Incidents Analysis":
        st.header("üëÅÔ∏è Incidents Analysis")
        if filtered.empty: st.warning("No data"); return

        t1, t2, t3, t4, t5 = st.tabs(["PSG9", "Groups (C/G)", "By Code", "Unresolved", "Safety Goals"])
        
        with t1:
            st.subheader("PSG9 Analysis")
            st.dataframe(create_psg9_summary_table(filtered), use_container_width=True)
        
        with t2:
            st.subheader("Clinical & General")
            if '‡∏´‡∏°‡∏ß‡∏î' in filtered.columns:
                st.dataframe(create_summary_table_by_category(filtered, '‡∏´‡∏°‡∏ß‡∏î'), use_container_width=True)
        
        with t3:
            st.subheader("Analysis By Code")
            st.dataframe(create_summary_table_by_code(filtered), use_container_width=True)
            
        with t4:
            st.subheader("Unresolved Items")
            unres = filtered[filtered['Resulting Actions'] == 'None']
            st.dataframe(unres[['Occurrence Date','Incident','Impact']], use_container_width=True)

        with t5:
            # --- FIX FOR TAB 5 ---
            st.subheader("Safety Goals Analysis")
            for disp, cat in goal_definitions.items():
                st.markdown(f"**{disp}**")
                is_org = (disp == "Organization Safety")
                # Correctly pass 'filtered' (the dataframe)
                tbl = create_goal_summary_table(filtered, cat, [], [], is_org)
                
                # Correct indentation for if/else
                if not tbl.empty:
                    st.dataframe(tbl, use_container_width=True)
                else:
                    st.info(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {disp}")
                st.markdown("---")

    # ----------------------------------------------------
    # Page: Risk Matrix
    # ----------------------------------------------------
    elif page == "Risk Matrix (Interactive)":
        st.header("Risk Matrix")
        if filtered.empty: st.warning("No data"); return
        
        # Simple Matrix Render
        mat = pd.crosstab(filtered['Impact Level'], filtered['Frequency Level'])
        st.dataframe(mat.style.background_gradient(cmap='Reds'), use_container_width=True)

    # ----------------------------------------------------
    # Page: Safety Goals (Summary)
    # ----------------------------------------------------
    elif page == "‡∏™‡∏£‡∏∏‡∏õ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ï‡∏≤‡∏° Safety Goals":
        st.header("Safety Goals Summary")
        if filtered.empty: st.warning("No data"); return
        
        for disp, cat in goal_definitions.items():
            st.subheader(disp)
            tbl = create_goal_summary_table(filtered, cat, [], [], disp=="Organization Safety")
            if not tbl.empty: st.dataframe(tbl, use_container_width=True)
            else: st.info("No Data")

    # ----------------------------------------------------
    # Page: Executive Summary
    # ----------------------------------------------------
    elif page == "‡∏ö‡∏ó‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£":
        st.header("üìë ‡∏ö‡∏ó‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£")
        st.info("Executive Summary Report Generation...")
        
        # Calculate Metrics
        total = len(filtered)
        sentinel = filtered['Sentinel code for check'].isin(sentinel_composite_keys).sum()
        severe = filtered['Impact Level'].isin(['3','4','5']).sum()
        
        html = f"""
        <div style="padding:20px; border:1px solid #ddd; border-radius:10px; background:white;">
            <h1 style="color:#003366; text-align:center;">Executive Summary</h1>
            <hr>
            <div style="display:flex; justify-content:space-around; margin-bottom:20px;">
                <div style="text-align:center;"><h3>Total</h3><h1>{total}</h1></div>
                <div style="text-align:center; color:red;"><h3>Sentinel</h3><h1>{sentinel}</h1></div>
                <div style="text-align:center; color:orange;"><h3>Severe</h3><h1>{severe}</h1></div>
            </div>
            <p>Generated on: {datetime.now().strftime('%d/%m/%Y')}</p>
        </div>
        """
        st.components.v1.html(html, height=400, scrolling=True)

    # ----------------------------------------------------
    # Page: Risk Register Assistant
    # ----------------------------------------------------
    elif page == "Risk Register Assistant":
        st.header("Risk Register Assistant")
        q = st.text_input("Search Code/Name")
        if st.button("Search") and q:
            with st.spinner("Analyzing..."):
                res = get_risk_register_consultation(q, filtered, df_mitigation)
                if "error" not in res:
                    st.success(f"Result for {res.get('incident_code')}")
                    st.json(res)
                else:
                    st.error("Not found or AI error.")

    # ----------------------------------------------------
    # Other Pages (Stubs for brevity)
    # ----------------------------------------------------
    elif page in ["Heatmap ‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô", "Sentinel Events & Top 10", "Persistence Risk Index", "Early Warning"]:
        st.header(page)
        if filtered.empty: st.warning("No Data"); return
        
        if page == "Sentinel Events & Top 10":
            st.subheader("Top 10 Incidents")
            top10 = filtered['Incident'].value_counts().head(10).reset_index()
            st.dataframe(top10, use_container_width=True)
            
        elif page == "Early Warning":
            st.subheader("Early Warning Signals")
            res = prioritize_incidents_nb_logit_v2(filtered)
            st.dataframe(res.head(10), use_container_width=True)
            
        else:
            st.info(f"Placeholder for {page}")

# ==============================================================================
# 5) MAIN ENTRY POINT
# ==============================================================================
def main():
    # 1. Load Data (Once)
    df = display_executive_dashboard()
    
    # 2. Render Interface (Pass Loaded Data)
    render_dashboard_interface(df)

if __name__ == "__main__":
    main()
