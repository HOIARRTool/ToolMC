# app.py (Restored Full Code without Anonymizer, with Department Filter, fixed Safety Goals & indents)
# -*- coding: utf-8 -*-
import os
import re
import unicodedata
from datetime import datetime, date
import numpy as np
import pandas as pd
import streamlit as st
from pathlib import Path
import base64
from dateutil.relativedelta import relativedelta
import statsmodels.api as sm
# from sklearn.linear_model import LinearRegression # Not used currently
import plotly.express as px
import plotly.graph_objects as go

# Keep AI/Risk Register imports (assuming files exist)
try:
    import google.generativeai as genai
except ImportError:
    genai = None

# Ensure these helper python files exist in the same directory or adjust path
try:
    from ai_assistant import get_consultation_response
except ImportError:
    def get_consultation_response(text): return f"Error: Could not import `get_consultation_response` from `ai_assistant.py`."
try:
    from risk_register_assistant import get_risk_register_consultation
except ImportError:
    def get_risk_register_consultation(query, df, risk_mitigation_df): return {"error": "Error: Could not import `get_risk_register_consultation` from `risk_register_assistant.py`."}

# Set page config first
st.set_page_config(layout="wide", page_title="HOIA-RR")

# =========================
# 0) ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô ‚Üî ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô
# =========================
SERVICE_MAP = [
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏™‡∏≤‡∏Ç‡∏≤‡∏Å‡∏∏‡∏°‡∏≤‡∏£‡πÄ‡∏ß‡∏ä‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏™‡∏≤‡∏Ç‡∏≤‡∏à‡∏±‡∏Å‡∏©‡∏∏‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏™‡∏≤‡∏Ç‡∏≤‡∏à‡∏¥‡∏ï‡πÄ‡∏ß‡∏ä‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡∏ô‡∏¥‡∏ï‡∏¥‡πÄ‡∏ß‡∏ä"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡∏û‡∏¢‡∏≤‡∏ò‡∏¥‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏Å‡∏≤‡∏¢‡∏ß‡∏¥‡∏†‡∏≤‡∏Ñ (PATHO)"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡∏û‡∏¢‡∏≤‡∏ò‡∏¥‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏Ñ‡∏•‡∏¥‡∏ô‡∏¥‡∏Å"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏î"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡∏£‡∏±‡∏á‡∏™‡∏µ‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•‡∏ß‡∏¥‡∏™‡∏±‡∏ç‡∏ç‡∏µ"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏™‡∏≤‡∏Ç‡∏≤‡∏ß‡∏¥‡∏™‡∏±‡∏ç‡∏ç‡∏µ‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡πÄ‡∏ß‡∏ä‡∏Å‡∏£‡∏£‡∏°‡∏™‡∏±‡∏á‡∏Ñ‡∏°"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏™‡∏≤‡∏Ç‡∏≤‡πÄ‡∏ß‡∏ä‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡∏ö‡πç‡∏≤‡∏ö‡∏±‡∏î"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏ï‡∏£‡∏ß‡∏à‡πÄ‡∏ß‡∏ä‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏ü‡∏∑‡πâ‡∏ô‡∏ü‡∏π"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏™‡∏≤‡∏Ç‡∏≤‡∏®‡∏±‡∏•‡∏¢‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏™‡∏≤‡∏Ç‡∏≤‡∏≠‡∏≠‡∏£‡πå‡πÇ‡∏ò‡∏õ‡∏¥‡∏î‡∏¥‡∏Å‡∏™‡πå"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏™‡∏≤‡∏Ç‡∏≤‡∏™‡∏π‡∏ï‡∏¥‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡πÅ‡∏•‡∏∞‡∏ô‡∏£‡∏µ‡πÄ‡∏ß‡∏ä‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏™‡∏≤‡∏Ç‡∏≤‡πÇ‡∏™‡∏ï ‡∏®‡∏≠ ‡∏ô‡∏≤‡∏™‡∏¥‡∏Å"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏™‡∏≤‡∏Ç‡∏≤‡∏≠‡∏≤‡∏¢‡∏∏‡∏£‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏Ñ‡∏•‡∏¥‡∏ô‡∏¥‡∏Å‡∏û‡∏¥‡πÄ‡∏®‡∏©‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏≤‡∏á‡∏ô‡∏≠‡∏Å‡πÄ‡∏ß‡∏•‡∏≤ (SMC)"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏Ñ‡∏•‡∏¥‡∏ô‡∏¥‡∏Å‡πÅ‡∏û‡∏ó‡∏¢‡πå‡πÅ‡∏ú‡∏ô‡πÑ‡∏ó‡∏¢"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏Ñ‡∏•‡∏¥‡∏ô‡∏¥‡∏Å‡πÅ‡∏û‡∏ó‡∏¢‡πå‡πÅ‡∏ú‡∏ô‡∏à‡∏µ‡∏ô"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏Ñ‡∏•‡∏¥‡∏ô‡∏¥‡∏Å‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏ö‡∏π‡∏£‡∏ì‡∏≤‡∏Å‡∏≤‡∏£"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡πÅ‡∏ú‡∏ô‡∏Å‡∏´‡πâ‡∏≠‡∏á‡∏¢‡∏≤‡∏™‡∏°‡∏∏‡∏ô‡πÑ‡∏û‡∏£"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡πÄ‡∏†‡∏™‡∏±‡∏ä‡∏Å‡∏£‡∏£‡∏°"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏Ñ‡∏•‡∏±‡∏á‡πÄ‡∏ß‡∏ä‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡∏°‡∏¥‡πÉ‡∏ä‡πà‡∏¢‡∏≤"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡πÇ‡∏†‡∏ä‡∏ô‡∏≤‡∏Å‡∏≤‡∏£"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏®‡∏π‡∏ô‡∏¢‡πå‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡πÅ‡∏û‡∏ó‡∏¢‡πå"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡πÇ‡∏•‡∏à‡∏¥‡∏™‡∏ï‡∏¥‡∏Å‡∏™‡πå‡πÅ‡∏•‡∏∞‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏¢‡πâ‡∏≤‡∏¢‡∏ú‡∏π‡πâ‡∏õ‡πâ‡∏ß‡∏¢"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡πÄ‡∏ß‡∏ä‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏õ‡∏•‡∏≠‡∏î‡πÄ‡∏ä‡∏∑‡πâ‡∏≠(CSSD)"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏ú‡πâ‡∏≤"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏™‡∏±‡∏á‡∏Ñ‡∏°‡∏™‡∏á‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "Admission center"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ô‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡πÄ‡∏ß‡∏ä‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡πÄ‡∏ß‡∏ä‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏à‡πà‡∏≤‡∏¢‡∏¢‡∏≤‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢ 11B"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡∏™‡∏ô‡∏±‡∏ö‡∏™‡∏ô‡∏∏‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡∏™‡πà‡∏á‡πÄ‡∏™‡∏£‡∏¥‡∏°‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡∏ô‡∏ß‡∏±‡∏ï‡∏Å‡∏£‡∏£‡∏°"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÅ‡∏•‡∏∞‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏ò‡∏£‡∏£‡∏°‡∏à‡∏£‡∏¥‡∏¢‡∏ò‡∏£‡∏£‡∏°"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÅ‡∏•‡∏∞‡∏¢‡∏∏‡∏ï‡∏¥‡∏ò‡∏£‡∏£‡∏°‡πÄ‡∏ä‡∏¥‡∏á‡∏™‡∏°‡∏≤‡∏ô‡∏â‡∏±‡∏ô‡∏ó‡πå"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏¢‡∏∏‡∏ó‡∏ò‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡πÅ‡∏•‡∏∞‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£‡∏¢‡∏∏‡∏ó‡∏ò‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏¢‡∏∏‡∏ó‡∏ò‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏™‡∏≤‡∏£‡∏™‡∏ô‡πÄ‡∏ó‡∏®"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡∏™‡∏≤‡∏£‡∏ö‡∏£‡∏£‡∏ì‡πÅ‡∏•‡∏∞‡∏≠‡∏≥‡∏ô‡∏ß‡∏¢‡∏Å‡∏≤‡∏£"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏®‡∏ß‡∏Å‡∏£‡∏£‡∏° (‡∏á‡∏≤‡∏ô‡∏≠‡∏≤‡∏Ñ‡∏≤‡∏£‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà)"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ï‡∏•‡∏≤‡∏î"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô‡∏ö‡∏±‡∏ç‡∏ä‡∏µ‡πÅ‡∏•‡∏∞‡∏á‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡∏û‡∏±‡∏™‡∏î‡∏∏"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô (ER)"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏ï‡∏£‡∏ß‡∏à‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏ï‡∏£‡∏ß‡∏à‡∏ï‡∏≤"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏ï‡∏£‡∏ß‡∏à‡∏´‡∏π ‡∏Ñ‡∏≠ ‡∏à‡∏°‡∏π‡∏Å"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏ï‡∏£‡∏ß‡∏à‡∏´‡∏±‡∏ß‡πÉ‡∏à‡πÅ‡∏•‡∏∞‡∏´‡∏•‡∏≠‡∏î‡πÄ‡∏•‡∏∑‡∏≠‡∏î ( OPD Heart )"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏ß‡∏ô‡∏´‡∏±‡∏ß‡πÉ‡∏à‡πÅ‡∏•‡∏∞‡∏´‡∏•‡∏≠‡∏î‡πÄ‡∏•‡∏∑‡∏≠‡∏î ( Cath Lab )"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏π‡∏ï‡∏¥‡∏ô‡∏£‡∏µ‡πÄ‡∏ß‡∏ä‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡πâ‡∏≠‡∏á‡∏Ñ‡∏•‡∏≠‡∏î"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏≠‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏™‡∏π‡∏ï‡∏¥‡∏ô‡∏£‡∏µ‡πÄ‡∏ß‡∏ä‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡πÅ‡∏•‡∏∞‡∏Å‡∏∏‡∏°‡∏≤‡∏£‡πÄ‡∏ß‡∏ä‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå 12 B"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏ï‡∏£‡∏ß‡∏à‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏ô‡∏≠‡∏Å‡∏®‡∏±‡∏•‡∏¢‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏ï‡∏£‡∏ß‡∏à‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏ô‡∏≠‡∏Å‡∏≠‡∏≠‡∏£‡πå‡πÇ‡∏ò‡∏õ‡∏¥‡∏î‡∏¥‡∏Å‡∏™‡πå"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏≠‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢ 8B"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏≠‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏™‡∏≤‡∏°‡∏±‡∏ç‡∏£‡∏ß‡∏° 9A"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏≠‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏û‡∏¥‡πÄ‡∏®‡∏©‡∏®‡∏±‡∏•‡∏¢‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå 10A"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏≠‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏û‡∏¥‡πÄ‡∏®‡∏©‡∏®‡∏±‡∏•‡∏¢‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå 11A"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏≠‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏û‡∏¥‡πÄ‡∏®‡∏©‡∏®‡∏±‡∏•‡∏¢‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡πÅ‡∏•‡∏∞‡∏≠‡∏≠‡∏£‡πå‡πÇ‡∏ò‡∏õ‡∏¥‡∏î‡∏¥‡∏Å‡∏™‡πå 12A"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏ï‡∏£‡∏ß‡∏à‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏ô‡∏≠‡∏Å‡∏≠‡∏≤‡∏¢‡∏∏‡∏£‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏≠‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢ CCU"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏≠‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡πÑ‡∏≠‡∏ã‡∏µ‡∏¢‡∏π‡∏≠‡∏≤‡∏¢‡∏∏‡∏£‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏≠‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏™‡∏≤‡∏°‡∏±‡∏ç‡∏≠‡∏≤‡∏¢‡∏∏‡∏£‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏´‡∏ç‡∏¥‡∏á 7A"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏≠‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏™‡∏≤‡∏°‡∏±‡∏ç‡∏≠‡∏≤‡∏¢‡∏∏‡∏£‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏ä‡∏≤‡∏¢ 7B"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏≠‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏û‡∏¥‡πÄ‡∏®‡∏©‡∏£‡∏ß‡∏° 10B"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡πÄ‡∏Ñ‡∏°‡∏µ‡∏ö‡∏≥‡∏ö‡∏±‡∏î 11B"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡πâ‡∏≠‡∏á‡πÑ‡∏ï‡πÄ‡∏ó‡∏µ‡∏¢‡∏°"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏ö‡∏≥‡∏ö‡∏±‡∏î‡∏ó‡∏î‡πÅ‡∏ó‡∏ô‡πÑ‡∏ï"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏ï‡∏£‡∏ß‡∏à‡πÄ‡∏î‡πá‡∏Å‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡∏î‡∏µ"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏ï‡∏£‡∏ß‡∏à‡∏£‡∏±‡∏Å‡∏©‡∏≤‡πÄ‡∏î‡πá‡∏Å‡∏õ‡πà‡∏ß‡∏¢"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏≠‡∏≠‡∏†‡∏¥‡∏ö‡∏≤‡∏•‡∏ó‡∏≤‡∏£‡∏Å‡πÅ‡∏£‡∏Å‡πÄ‡∏Å‡∏¥‡∏î (Nursery)"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡∏à‡∏¥‡∏ï"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏≠‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏™‡∏≤‡∏°‡∏±‡∏ç‡∏à‡∏¥‡∏ï‡πÄ‡∏ß‡∏ä (8A)"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•‡∏ú‡πà‡∏≤‡∏ï‡∏±‡∏î"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏™‡πà‡∏≠‡∏á‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡∏≤‡∏á‡πÄ‡∏î‡∏¥‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏™‡πà‡∏á‡πÄ‡∏™‡∏£‡∏¥‡∏°‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û (Check-up)"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏•‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡πÉ‡∏ô‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏ß‡∏¥‡∏Å‡∏§‡∏ï‡∏≠‡∏≤‡∏¢‡∏∏‡∏£‡∏Å‡∏£‡∏£‡∏°"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•‡∏´‡πâ‡∏≠‡∏á‡∏Ñ‡∏•‡∏≠‡∏î‡πÅ‡∏•‡∏∞‡∏ó‡∏≤‡∏£‡∏Å‡πÅ‡∏£‡∏Å‡πÄ‡∏Å‡∏¥‡∏î (‡∏á‡∏≤‡∏ô‡∏≠‡∏≤‡∏™‡∏≤‡∏™‡∏°‡∏±‡∏Ñ‡∏£)"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "‡∏´‡∏≠‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏™‡∏≤‡∏°‡∏±‡∏ç‡πÄ‡∏î‡πá‡∏Å ‡∏ä‡∏±‡πâ‡∏ô 9B"},
    {"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô": "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "300503"},
]
REF_DF = pd.DataFrame(SERVICE_MAP)
REF_COL = "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô"  # Column name in the main data file for department

def list_units(group_name: str) -> list:
    if not group_name or group_name in ("-- ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô --", "-- ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î --"):
        return []
    if group_name in REF_DF["‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô"].unique():
        return sorted(REF_DF.loc[REF_DF["‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô"] == group_name, "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô"].unique().tolist())
    return []

# =========================
# A) Normalization & Mapping
# =========================
INVIS_CHARS = {"\u200b": "", "\u200c": "", "\u200d": "", "\ufeff": ""}
PARENS = {"Ôºà": "(", "Ôºâ": ")", "Ôπô": "(", "Ôπö": ")", "‚Äú": '"', "‚Äù": '"', "‚Äò": "'", "‚Äô": "'"}
TRANS_INVIS = str.maketrans(INVIS_CHARS)
TRANS_PARENS = str.maketrans(PARENS)
ALIASES = {
    "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡πÇ‡∏•‡∏à‡∏¥‡∏™‡∏ï‡∏¥‡∏Å‡∏™‡πå‡πÅ‡∏•‡∏∞‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏¢‡πâ‡∏≤‡∏¢‡∏ú‡∏π‡πâ‡∏õ‡πâ‡∏ß‡∏¢": "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡πÇ‡∏•‡∏à‡∏¥‡∏™‡∏ï‡∏¥‡∏Å‡∏™‡πå‡πÅ‡∏•‡∏∞‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏¢‡πâ‡∏≤‡∏¢‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢",
}

def normalize_unit(text: str) -> str:
    if pd.isna(text): return ""
    s = str(text)
    s = unicodedata.normalize("NFKC", s)
    s = s.replace("\xa0", " ").translate(TRANS_INVIS).translate(TRANS_PARENS)
    s = re.sub(r"\s+", " ", s.strip()).strip('\'"')
    return ALIASES.get(s, s)

service_map_norm = {normalize_unit(r["‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô"]): r["‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô"] for r in SERVICE_MAP}

# === Safety Goals definitions (global) ===
goal_definitions = {
    "Patient Safety/ Common Clinical Risk": "P:Patient Safety Goals ‡∏´‡∏£‡∏∑‡∏≠ Common Clinical Risk Incident",
    "Specific Clinical Risk": "S:Specific Clinical Risk Incident",
    "Personnel Safety": "P:Personnel Safety Goals",
    "Organization Safety": "O:Organization Safety Goals",
}

# =========================
# 1) ‡πÅ‡∏õ‡∏•‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà/‡πÄ‡∏ß‡∏•‡∏≤‡πÑ‡∏ó‡∏¢ ‚Üí Timestamp
# =========================
THAI_MONTHS = {
    "‡∏°.‡∏Ñ.":1, "‡∏Å.‡∏û.":2, "‡∏°‡∏µ.‡∏Ñ.":3, "‡πÄ‡∏°.‡∏¢.":4, "‡∏û.‡∏Ñ.":5, "‡∏°‡∏¥.‡∏¢.":6,
    "‡∏Å.‡∏Ñ.":7, "‡∏™.‡∏Ñ.":8, "‡∏Å.‡∏¢.":9, "‡∏ï.‡∏Ñ.":10, "‡∏û.‡∏¢.":11, "‡∏ò.‡∏Ñ.":12,
    "‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°":1, "‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå":2, "‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°":3, "‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô":4, "‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°":5, "‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô":6,
    "‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°":7, "‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°":8, "‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô":9, "‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°":10, "‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô":11, "‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°":12,
}
THAI_DIGITS = "‡πê‡πë‡πí‡πì‡πî‡πï‡πñ‡πó‡πò‡πô"; ARABIC_DIGITS = "0123456789"
DIGIT_MAP = str.maketrans({t: a for t, a in zip(THAI_DIGITS, ARABIC_DIGITS)})

def normalize_raw_datetime_text(x):
    if x is None or (isinstance(x, float) and pd.isna(x)) or (isinstance(x, str) and x.strip() == ""): return None
    s = str(x).strip().translate(DIGIT_MAP)
    s = re.sub(r"\b‡πÄ‡∏ß‡∏•‡∏≤\b", "", s); s = re.sub(r"\s*‡∏ô\.?\b", "", s); s = re.sub(r"\s+", " ", s).strip()
    return s if s else None

def parse_incident_datetime(value):
    # Handle direct Timestamp or datetime objects
    if isinstance(value, (pd.Timestamp, datetime)):
        ts = pd.Timestamp(value)
        if ts.year >= 2400:
            ts = ts - pd.DateOffset(years=543)
        return ts

    # Handle Excel numeric date format (days since 1899-12-30)
    try:
        if isinstance(value, (int, float)) and not pd.isna(value):
            return pd.to_datetime(value, unit="d", origin="1899-12-30", errors="coerce")
        # numeric string like "45678.0"
        v = str(value)
        if re.fullmatch(r"\d+(\.\d+)?", v):
            return pd.to_datetime(float(v), unit="d", origin="1899-12-30", errors="coerce")
    except Exception:
        pass

    # Handle string formats
    s = normalize_raw_datetime_text(value)
    if not s:
        return pd.NaT

    # Thai month: dd Mon yyyy [HH:MM[:SS]]
    # --- ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏ß‡∏á‡πÄ‡∏•‡πá‡∏ö‡∏ä‡∏±‡πâ‡∏ô‡πÉ‡∏ô‡πÄ‡∏õ‡πá‡∏ô non-capturing ‡∏î‡πâ‡∏ß‡∏¢ (?::\d{2})? ---
    m_th = re.search(r"(\d{1,2})\s*([‡∏Å-‡πô\.]+)\s*(\d{4})\s*(\d{1,2}:\d{2}(?::\d{2})?)?", s)
    if m_th:
        dd_str = m_th.group(1)
        mon_txt = m_th.group(2)
        yyyy_str = m_th.group(3)
        hhmmss_str = m_th.group(4)  # ‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô None
        dd = int(dd_str)
        yyyy = int(yyyy_str)
        hhmmss = hhmmss_str or "00:00:00"
        # ‡πÄ‡∏ï‡∏¥‡∏°‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
        if len(hhmmss) == 5:
            hhmmss = hhmmss + ":00"
        mm = THAI_MONTHS.get(mon_txt.strip()) or THAI_MONTHS.get(mon_txt.strip() + ".")
        if mm:
            if yyyy >= 2400:
                yyyy -= 543
            try:
                return pd.to_datetime(f"{yyyy:04d}-{mm:02d}-{dd:02d} {hhmmss}",
                                      format="%Y-%m-%d %H:%M:%S", errors="coerce")
            except ValueError:
                pass

    # dd/mm/yyyy or dd-mm-yyyy [HH:MM[:SS]]
    m_sep = re.search(r"(\d{1,2})[/-](\d{1,2})[/-](\d{4})(?:\s+(\d{1,2}:\d{2}(?::\d{2})?))?", s)
    if m_sep:
        dd_str = m_sep.group(1)
        mm_str = m_sep.group(2)
        yyyy_str = m_sep.group(3)
        hhmmss_str = m_sep.group(4)  # ‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô None
        dd = int(dd_str)
        mm = int(mm_str)
        yyyy = int(yyyy_str)
        hhmmss = hhmmss_str or "00:00:00"
        if len(hhmmss) == 5:
            hhmmss = hhmmss + ":00"
        if yyyy >= 2400:
            yyyy -= 543
        try:
            return pd.to_datetime(f"{yyyy:04d}-{mm:02d}-{dd:02d} {hhmmss}",
                                  format="%Y-%m-%d %H:%M:%S", errors="coerce")
        except ValueError:
            pass

    # Fallback: ‡πÅ‡∏õ‡∏•‡∏á‡∏õ‡∏µ ‡∏û.‡∏®. ‡πÄ‡∏õ‡πá‡∏ô ‡∏Ñ.‡∏®. ‡∏ñ‡πâ‡∏≤‡∏û‡∏ö
    yr = re.search(r"\b(2\d{3})\b", s)
    if yr:
        y = int(yr.group(1))
        if y >= 2400:
            s = s.replace(str(y), str(y - 543), 1)

    # Final fallback
    return pd.to_datetime(s, dayfirst=True, errors="coerce")


# =========================
# 2) Risk / ‡∏™‡∏µ
# =========================
def map_impact_level_func(val):
    s = str(val).strip().upper()
    if s in ("A", "B", "1"): return "1"
    if s in ("C", "D", "2"): return "2"
    if s in ("E", "F", "3"): return "3"
    if s in ("G", "H", "4"): return "4"
    if s in ("I", "5"): return "5"
    return "N/A"

RISK_COLOR_TABLE = {
    "11":"Low","12":"Low","13":"Low","14":"Medium","15":"Medium",
    "21":"Low","22":"Low","23":"Medium","24":"Medium","25":"High",
    "31":"Low","32":"Medium","33":"Medium","34":"High","35":"High",
    "41":"Medium","42":"Medium","43":"High","44":"High","45":"Extreme",
    "51":"Medium","52":"High","53":"High","54":"Extreme","55":"Extreme",
}

def compute_frequency_level(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty or 'Occurrence Date' not in df.columns or df['Occurrence Date'].isna().all():
        return df.assign(**{'count':0, 'Incident Rate/mth':0.0, 'Frequency Level':'N/A'})
    max_p = df['Occurrence Date'].max().to_period('M'); min_p = df['Occurrence Date'].min().to_period('M')
    total_month_calc = max(1, (max_p.year - min_p.year) * 12 + (max_p.month - min_p.month) + 1)
    counts = df['Incident'].value_counts(); out = df.copy()
    out['count'] = out['Incident'].map(counts).fillna(0).astype(int)
    out['Incident Rate/mth'] = (out['count'] / total_month_calc).round(1)
    cond = [(out['Incident Rate/mth']<2.0), (out['Incident Rate/mth']<3.9), (out['Incident Rate/mth']<6.9), (out['Incident Rate/mth']<29.9)]
    out['Frequency Level'] = np.select(cond, ['1','2','3','4'], default='5')
    return out

def build_risk_matrix(df: pd.DataFrame) -> pd.DataFrame:
    idx = list("54321"); cols = list("12345"); empty_mat = pd.DataFrame(0, index=idx, columns=cols)
    if df.empty or 'Risk Level' not in df.columns: return empty_mat
    valid_df = df[(df['Risk Level'] != 'N/A') & df['Impact Level'].isin(idx) & df['Frequency Level'].isin(cols)]
    if valid_df.empty: return empty_mat
    mat = pd.crosstab(valid_df['Impact Level'], valid_df['Frequency Level'])
    return mat.reindex(index=idx, columns=cols, fill_value=0)

def summarize_max_risk_per_incident(df: pd.DataFrame) -> pd.DataFrame:
    cols=['Incident','‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á','Max Risk','Category Color']
    if df.empty or 'Risk Level' not in df.columns: return pd.DataFrame(columns=cols)
    order={'1':1,'2':2,'3':3,'4':4,'5':5}; d2 = df[df['Risk Level'] != 'N/A'].copy()
    if d2.empty: return pd.DataFrame(columns=cols)
    d2['I_num'] = d2['Impact Level'].map(order).fillna(0).astype(int); d2['F_num'] = d2['Frequency Level'].map(order).fillna(0).astype(int)
    d2['score'] = d2['I_num']*10 + d2['F_num']
    idx = d2.groupby(['Incident','‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á'], observed=True)['score'].idxmax()
    agg = d2.loc[idx, ['Incident','‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á','Risk Level','Category Color','Incident Rate/mth']].copy()
    agg = agg.rename(columns={'Risk Level':'Max Risk', 'Incident Rate/mth':'rate'})
    return agg.sort_values('rate', ascending=False).drop(columns='rate')

# =========================
# 3) ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå & ‡∏à‡∏±‡∏î‡∏™‡∏Ñ‡∏µ‡∏°‡∏≤
# =========================
def read_uploaded_table(uploaded_file) -> pd.DataFrame:
    if uploaded_file is None: return pd.DataFrame()
    name = uploaded_file.name.lower()
    try:
        if name.endswith(".csv"): return pd.read_csv(uploaded_file)
        elif name.endswith((".xlsx", ".xls")): return pd.read_excel(uploaded_file, engine="openpyxl")
        else: raise ValueError("‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö .csv, .xlsx, .xls")
    except Exception as e:
        st.error(f"Error reading file '{uploaded_file.name}': {e}")
        return pd.DataFrame()

def massage_schema(df: pd.DataFrame) -> pd.DataFrame:
    required = ["‡∏£‡∏´‡∏±‡∏™‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠","‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠","‡∏ß‡∏±‡∏ô-‡πÄ‡∏ß‡∏•‡∏≤ ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏´‡∏ï‡∏∏","‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á", REF_COL]
    missing = [c for c in required if c not in df.columns]
    if missing:
        st.error("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô: " + ", ".join(missing)); st.stop()

    df = df.copy()
    # Strip whitespace from all string columns first for consistency
    for col in df.select_dtypes(include='object').columns:
        if col not in ['Occurrence Date']:
            df[col] = df[col].astype(str).str.strip()

    df["‡∏£‡∏´‡∏±‡∏™: ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå"] = df["‡∏£‡∏´‡∏±‡∏™‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠"] + ": " + df["‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠"]
    df["Incident"] = df["‡∏£‡∏´‡∏±‡∏™‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠"]
    df = df[df["Incident"] != ""].copy()
    df["‡∏£‡∏´‡∏±‡∏™"] = df["Incident"].astype(str).str.slice(0,6)
    df["‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á"] = df["‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠"]

    df.rename(columns={"‡∏ß‡∏±‡∏ô-‡πÄ‡∏ß‡∏•‡∏≤ ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏´‡∏ï‡∏∏": "Occurrence Date"}, inplace=True)
    converted = df["Occurrence Date"].apply(parse_incident_datetime)
    bad = converted.isna().sum()
    if bad > 0: st.warning(f"‡∏Ç‡πâ‡∏≤‡∏° {bad} ‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ú‡∏¥‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö")
    df["Occurrence Date"] = converted
    df.dropna(subset=["Occurrence Date"], inplace=True)
    if df.empty: st.error("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á"); st.stop()

    df["Impact"] = df["‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á"].astype(str).str.upper()
    df['Sentinel code for check'] = df['‡∏£‡∏´‡∏±‡∏™'].astype(str).str.strip() + '-' + df['Impact'].astype(str).str.strip()
    df['Impact Level'] = df['Impact'].apply(map_impact_level_func)
    df = compute_frequency_level(df)
    df['Risk Level'] = np.where((df['Impact Level']!='N/A') & (df['Frequency Level'].notna()), df['Impact Level']+df['Frequency Level'], 'N/A')
    df['Category Color'] = df['Risk Level'].map(RISK_COLOR_TABLE).fillna('Undefined')

    df['Incident Type'] = df['Incident'].astype(str).str[:3]
    df['Month'] = df['Occurrence Date'].dt.month
    month_label_map = {1:"‡∏°.‡∏Ñ.",2:"‡∏Å.‡∏û.",3:"‡∏°‡∏µ.‡∏Ñ.",4:"‡πÄ‡∏°.‡∏¢.",5:"‡∏û.‡∏Ñ.",6:"‡∏°‡∏¥.‡∏¢.",7:"‡∏Å.‡∏Ñ.",8:"‡∏™.‡∏Ñ.",9:"‡∏Å.‡∏¢.",10:"‡∏ï.‡∏Ñ.",11:"‡∏û.‡∏¢.",12:"‡∏ò.‡∏Ñ."}
    df['‡πÄ‡∏î‡∏∑‡∏≠‡∏ô'] = df['Month'].map(month_label_map)
    df['Year'] = df['Occurrence Date'].dt.year.astype(str)

    # Normalize unit names before mapping
    df["‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô_norm"] = df[REF_COL].apply(normalize_unit)
    df["‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô"] = df["‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô_norm"].map(service_map_norm).fillna("N/A")

    action_col_original = "‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£/‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡πÑ‡∏õ‡πÅ‡∏•‡πâ‡∏ß"
    if "Resulting Actions" not in df.columns:
        if action_col_original in df.columns:
            df['Resulting Actions'] = df[action_col_original].astype(str).apply(
                lambda x: 'None' if x.strip() == '' or x.strip().lower() == 'none' or pd.isna(x) else x
            ).fillna('None')
        else:
            df["Resulting Actions"] = "None"

        # --- PSG9 & ‡∏´‡∏°‡∏ß‡∏î Mapping ---
        # (PSG9code_df_master ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ global ‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ß‡πâ‡πÉ‡∏ô Section 5)
        if 'PSG9code_df_master' in globals() and not PSG9code_df_master.empty and '‡∏£‡∏´‡∏±‡∏™' in PSG9code_df_master.columns:

            # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÑ‡∏ü‡∏•‡πå PSG9 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö merge
            cols_to_merge = ['‡∏£‡∏´‡∏±‡∏™']
            if '‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πàPSG' in PSG9code_df_master.columns:
                cols_to_merge.append('‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πàPSG')
            if '‡∏´‡∏°‡∏ß‡∏î' in PSG9code_df_master.columns:
                cols_to_merge.append('‡∏´‡∏°‡∏ß‡∏î')

            psg9_to_merge = PSG9code_df_master[cols_to_merge].drop_duplicates(subset=['‡∏£‡∏´‡∏±‡∏™'])

            # ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '‡∏£‡∏´‡∏±‡∏™' ‡πÄ‡∏õ‡πá‡∏ô str ‡∏ó‡∏±‡πâ‡∏á‡∏Ñ‡∏π‡πà‡πÄ‡∏û‡∏∑‡πà‡∏≠ merge
            df['‡∏£‡∏´‡∏±‡∏™'] = df['‡∏£‡∏´‡∏±‡∏™'].astype(str)
            psg9_to_merge['‡∏£‡∏´‡∏±‡∏™'] = psg9_to_merge['‡∏£‡∏´‡∏±‡∏™'].astype(str)

            # --- ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ Merge ---
            df = df.merge(psg9_to_merge, on='‡∏£‡∏´‡∏±‡∏™', how='left')

            # --- 1. ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç' ---
            if '‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πàPSG' in df.columns:
                # ‡∏ñ‡πâ‡∏≤ merge ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à, ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏°‡∏≤, ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà (‡πÑ‡∏î‡πâ‡∏Ñ‡πà‡∏≤ NaN) ‡πÉ‡∏´‡πâ‡πÄ‡∏ï‡∏¥‡∏° "‡πÑ‡∏°‡πà‡∏à‡∏±‡∏î‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô..."
                df['‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç'] = df['‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πàPSG'].fillna("‡πÑ‡∏°‡πà‡∏à‡∏±‡∏î‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô PSG9 Catalog")
                df = df.drop(columns=['‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πàPSG'])  # ‡∏•‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà merge ‡∏°‡∏≤‡∏ó‡∏¥‡πâ‡∏á
            else:
                # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏ü‡∏•‡πå PSG9code.xlsx ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πàPSG'
                df["‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç"] = "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏ (‡πÑ‡∏°‡πà‡∏°‡∏µ '‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πàPSG' ‡πÉ‡∏ô PSG9code.xlsx)"

            # --- 2. ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '‡∏´‡∏°‡∏ß‡∏î' (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Safety Goals / C,G analysis) ---
            if '‡∏´‡∏°‡∏ß‡∏î' in df.columns:
                # ‡∏ñ‡πâ‡∏≤ merge ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à, ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏°‡∏≤, ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà (‡πÑ‡∏î‡πâ‡∏Ñ‡πà‡∏≤ NaN) ‡πÉ‡∏´‡πâ‡πÄ‡∏ï‡∏¥‡∏° "N/A"
                df['‡∏´‡∏°‡∏ß‡∏î'] = df['‡∏´‡∏°‡∏ß‡∏î'].fillna("N/A")
            else:
                # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏ü‡∏•‡πå PSG9code.xlsx ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '‡∏´‡∏°‡∏ß‡∏î'
                df["‡∏´‡∏°‡∏ß‡∏î"] = "N/A"
                st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '‡∏´‡∏°‡∏ß‡∏î' ‡πÉ‡∏ô PSG9code.xlsx - ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå Safety Goals ‡πÅ‡∏•‡∏∞ C/G ‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•")

        else:
            # ‡∏ñ‡πâ‡∏≤‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå PSG9code.xlsx ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡πÅ‡∏£‡∏Å
            st.error("‚ùå PSG9 mapping ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: ‡πÑ‡∏°‡πà‡∏û‡∏ö 'PSG9code.xlsx' ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤")
            df["‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç"] = "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏ (PSG9code.xlsx ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÇ‡∏´‡∏•‡∏î/‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô)"
            df["‡∏´‡∏°‡∏ß‡∏î"] = "N/A"

        # --- END Mapping ---

    detail_col_original = "‡∏™‡∏£‡∏∏‡∏õ‡∏õ‡∏±‡∏ç‡∏´‡∏≤/‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÇ‡∏î‡∏¢‡∏¢‡πà‡∏≠"
    if detail_col_original in df.columns:
        df["‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î_Anonymized"] = df[detail_col_original].fillna('')
    else:
        df["‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î_Anonymized"] = ''
    df.rename(columns={detail_col_original: "‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î"}, inplace=True, errors='ignore')

    cols_to_convert = ['self_report', 'potential_harm']
    for col in cols_to_convert:
        if col in df.columns:
            df[col] = df[col].replace(['None', ''], np.nan)
            df[col] = pd.to_numeric(df[col], errors='coerce')

    if REF_COL not in df.columns: df[REF_COL] = "N/A"
    df[REF_COL] = df[REF_COL].astype(str).fillna("N/A")
    return df

# =========================
# 4) Time parts (Fiscal Year) + ‡∏ü‡∏¥‡∏•‡πÄ‡∏ï‡∏≠‡∏£‡πå
# =========================
TH_MONTH_TINY = {1:"‡∏°.‡∏Ñ.",2:"‡∏Å.‡∏û.",3:"‡∏°‡∏µ.‡∏Ñ.",4:"‡πÄ‡∏°.‡∏¢.",5:"‡∏û.‡∏Ñ.",6:"‡∏°‡∏¥.‡∏¢.",7:"‡∏Å.‡∏Ñ.",8:"‡∏™.‡∏Ñ.",9:"‡∏Å.‡∏¢.",10:"‡∏ï.‡∏Ñ.",11:"‡∏û.‡∏¢.",12:"‡∏ò.‡∏Ñ."}

def add_time_parts_fiscal(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty or 'Occurrence Date' not in df.columns: return df
    out=df.copy(); out['Year_int']=out['Occurrence Date'].dt.year.astype(int); out['Month_int']=out['Occurrence Date'].dt.month.astype(int)
    out['FY_int'] = np.where(out['Month_int'] >= 10, out['Year_int'] + 1, out['Year_int']).astype(int)
    def _fq(m): return 'Q1' if m in (10,11,12) else ('Q2' if m in (1,2,3) else ('Q3' if m in (4,5,6) else 'Q4'))
    out['FQuarter'] = out['Month_int'].apply(_fq).astype(str); out['FY_Quarter'] = out['FY_int'].astype(str) + '-' + out['FQuarter']
    return out

def filter_by_period_fiscal(df: pd.DataFrame, mode: str, fy: str|int|None=None, fq: str|None=None, m: int|None=None) -> pd.DataFrame:
    if df.empty or mode == "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î": return df
    out = df.copy()
    fy_str = str(fy) if fy not in (None, "", "-- ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î --") else None
    if mode == "‡∏£‡∏≤‡∏¢‡∏õ‡∏µ" and fy_str and 'FY_int' in out.columns: out = out[out['FY_int'].astype(str) == fy_str]
    elif mode == "‡∏£‡∏≤‡∏¢‡πÑ‡∏ï‡∏£‡∏°‡∏≤‡∏™":
        if fy_str and 'FY_int' in out.columns: out = out[out['FY_int'].astype(str) == fy_str]
        if fq and fq != "-- ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î --" and 'FQuarter' in out.columns: out = out[out['FQuarter'] == fq]
    elif mode == "‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô":
        if fy_str and 'FY_int' in out.columns: out = out[out['FY_int'].astype(str) == fy_str]
        if m and m != "-- ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î --" and 'Month_int' in out.columns: out = out[out['Month_int'].astype(int) == int(m)]
    return out

def filter_by_group_and_unit(df: pd.DataFrame, group_name: str, unit_name: str) -> pd.DataFrame:
    if df.empty: return df
    out = df.copy()
    # ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô
    if group_name not in (None, "", "-- ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô --", "-- ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î --"):
        out = out[out["‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô"].astype(str) == str(group_name)]
    # ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô
    if unit_name not in (None, "", "-- ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î --"):
        out = out[out[REF_COL].astype(str) == str(unit_name)]
    return out

# =========================
# 5) UI (Main Structure)
# =========================
LOGO_URL = "https://raw.githubusercontent.com/HOIARRTool/hoiarr/refs/heads/main/logo1.png"
month_label = {1:"‡∏°.‡∏Ñ.",2:"‡∏Å.‡∏û.",3:"‡∏°‡∏µ.‡∏Ñ.",4:"‡πÄ‡∏°.‡∏¢.",5:"‡∏û.‡∏Ñ.",6:"‡∏°‡∏¥.‡∏¢.",7:"‡∏Å.‡∏Ñ.",8:"‡∏™.‡∏Ñ.",9:"‡∏Å.‡∏¢.",10:"‡∏ï.‡∏Ñ.",11:"‡∏û.‡∏¢.",12:"‡∏ò.‡∏Ñ."}

# --- Static Definitions ---
DATA_DIR = Path("data"); DATA_DIR.mkdir(exist_ok=True)
PERSISTED_DATA_PATH = DATA_DIR / "processed_incident_data.parquet"
PSG9_FILE_PATH = "PSG9code.xlsx"
SENTINEL_FILE_PATH = "Sentinel2024.xlsx"
RISK_MITIGATION_FILE = "risk_mitigations.xlsx"
#DEPARTMENT_FILE_PATH = "service point.xlsx - 53 ‡∏á‡∏≤‡∏ô (‡∏ó‡∏∏‡∏Å‡∏ù‡πà‡∏≤‡∏¢).csv"

psg9_r_codes_for_counting = set()
sentinel_composite_keys = set()
df_mitigation = pd.DataFrame()
department_list = []
PSG9_label_dict = {}

try:
    if Path(PSG9_FILE_PATH).is_file():
        PSG9code_df_master = pd.read_excel(PSG9_FILE_PATH)
        if '‡∏£‡∏´‡∏±‡∏™' in PSG9code_df_master.columns:
            psg9_r_codes_for_counting = set(PSG9code_df_master['‡∏£‡∏´‡∏±‡∏™'].astype(str).str.strip().unique())
        if 'PSG_ID' in PSG9code_df_master.columns and '‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πàPSG' in PSG9code_df_master.columns:
            PSG9_label_dict = pd.Series(PSG9code_df_master['‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πàPSG'].values,
                                        index=PSG9code_df_master.PSG_ID).to_dict()
        else:
            st.sidebar.warning(f"'{PSG9_FILE_PATH}' ‡πÑ‡∏°‡πà‡∏°‡∏µ PSG_ID ‡∏´‡∏£‡∏∑‡∏≠ ‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πàPSG")
    else:
        st.sidebar.warning(f"‡πÑ‡∏°‡πà‡∏û‡∏ö '{PSG9_FILE_PATH}'")

    if Path(SENTINEL_FILE_PATH).is_file():
        Sentinel2024_df = pd.read_excel(SENTINEL_FILE_PATH)
        if '‡∏£‡∏´‡∏±‡∏™' in Sentinel2024_df.columns and 'Impact' in Sentinel2024_df.columns:
            Sentinel2024_df['‡∏£‡∏´‡∏±‡∏™'] = Sentinel2024_df['‡∏£‡∏´‡∏±‡∏™'].astype(str).str.strip()
            Sentinel2024_df['Impact'] = Sentinel2024_df['Impact'].astype(str).str.strip()
            Sentinel2024_df.dropna(subset=['‡∏£‡∏´‡∏±‡∏™', 'Impact'], inplace=True)
            sentinel_composite_keys = set((Sentinel2024_df['‡∏£‡∏´‡∏±‡∏™'] + '-' + Sentinel2024_df['Impact']).unique())
    else:
        st.sidebar.warning(f"‡πÑ‡∏°‡πà‡∏û‡∏ö '{SENTINEL_FILE_PATH}'")

    if Path(RISK_MITIGATION_FILE).is_file():
        df_mitigation = pd.read_excel(RISK_MITIGATION_FILE)
    else:
        st.sidebar.warning(f"‡πÑ‡∏°‡πà‡∏û‡∏ö '{RISK_MITIGATION_FILE}'")

    #if Path(DEPARTMENT_FILE_PATH).is_file():
        #dept_df = pd.read_csv(DEPARTMENT_FILE_PATH)
        #if '‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô' in dept_df.columns:
            #department_list = sorted([dept for dept in dept_df['‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô'].astype(str).unique()
                                      #if dept and pd.notna(dept) and dept.strip() != ''])
        #else:
            #st.sidebar.error(f"‡πÑ‡∏°‡πà‡∏û‡∏ö '‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô' ‡πÉ‡∏ô '{DEPARTMENT_FILE_PATH}'")
    #else:
        #st.sidebar.error(f"‡πÑ‡∏°‡πà‡∏û‡∏ö '{DEPARTMENT_FILE_PATH}'")

except Exception as e:
    st.sidebar.error(f"‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏¥‡∏¢‡∏≤‡∏°/‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")

# Other static vars
risk_color_data = {
    'Category Color': ["Critical", "Critical", "Critical", "Critical", "Critical", "High", "High", "Critical", "Critical", "Critical",
                       "Medium", "Medium", "High", "Critical", "Critical", "Low", "Medium", "Medium", "High", "High", "Low", "Low", "Low", "Medium", "Medium"],
    'Risk Level': ["51", "52", "53", "54", "55", "41", "42", "43", "44", "45", "31", "32", "33", "34", "35", "21", "22", "23", "24", "25", "11", "12", "13", "14", "15"]}
risk_color_df = pd.DataFrame(risk_color_data)
display_cols_common = ['Occurrence Date', '‡∏£‡∏´‡∏±‡∏™', '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á', 'Impact', 'Impact Level',
                       '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î_Anonymized', 'Resulting Actions', '‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô']
type_name = {'CPS': 'Safe Surgery', 'CPI': 'Infection Control', 'CPM': 'Medication & Blood Safety', 'CPP': 'Patient Care Process',
             'CPL': 'Line, Tube & Catheter, Lab', 'CPE': 'Emergency Response', 'CSG': 'Gyn & Obs', 'CSS': 'Surgical', 'CSM': 'Medical',
             'CSP': 'Pediatric', 'CSO': 'Orthopedic', 'CSD': 'Dental', 'GPS': 'Social Media & Comms', 'GPI': 'Infection & Exposure',
             'GPM': 'Mental Health & Mediation', 'GPP': 'Process of work', 'GPL': 'Lane & Legal', 'GPE': 'Environment & Working',
             'GOS': 'Strategy, Structure, Security', 'GOI': 'IT & Comms, Internal control', 'GOM': 'Manpower, Management',
             'GOP': 'Policy, Process & Operation', 'GOL': 'Licensed & Professional cert', 'GOE': 'Economy'}
colors2 = np.array([["#e1f5fe","#f6c8b6","#dd191d","#dd191d","#dd191d","#dd191d","#dd191d"],
                    ["#e1f5fe","#f6c8b6","#ff8f00","#ff8f00","#dd191d","#dd191d","#dd191d"],
                    ["#e1f5fe","#f6c8b6","#ffee58","#ffee58","#ff8f00","#dd191d","#dd191d"],
                    ["#e1f5fe","#f6c8b6","#42db41","#ffee58","#ffee58","#ff8f00","#ff8f00"],
                    ["#e1f5fe","#f6c8b6","#42db41","#42db41","#42db41","#ffee58","#ffee58"],
                    ["#e1f5fe","#f6c8b6","#f6c8b6","#f6c8b6","#f6c8b6","#f6c8b6","#f6c8b6"],
                    ["#e1f5fe","#e1f5fe","#e1f5fe","#e1f5fe","#e1f5fe","#e1f5fe","#e1f5fe"]])

# --- Sidebar ---
with st.sidebar:
    st.markdown(f"""<div style="display: flex; align-items: center; margin-bottom: 1rem;"><img src="{LOGO_URL}" style="height: 32px; margin-right: 10px;"><h2 style="margin: 0; font-size: 1.7rem;"><span class="gradient-text">HOIA-RR Menu</span></h2></div>""", unsafe_allow_html=True)
    # --- Upload and Filters ---
    st.header("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    up = st.file_uploader(
        "‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå (.xlsx)",
        type=["csv", "xlsx", "xls"],
        key="main_uploader"
    )

    st.header("‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏Å")
    GROUP_OPTIONS = ["-- ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô --", "-- ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î --"] + sorted(REF_DF["‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô"].unique().tolist())
    sel_group = st.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô", GROUP_OPTIONS, index=1)
    if sel_group == "-- ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î --":
        sel_unit = "-- ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î --"
        st.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô", ["-- ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î --"], index=0, disabled=True)
    else:
        unit_options = list_units(sel_group)
        sel_unit = st.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô", ["-- ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î --"] + unit_options, index=0, disabled=(sel_group in ("", "-- ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô --")))
    st.header("‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤ (‡∏õ‡∏µ‡∏á‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì)")
    period_mode = st.selectbox("‡πÇ‡∏´‡∏°‡∏î‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤", ["‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", "‡∏£‡∏≤‡∏¢‡∏õ‡∏µ", "‡∏£‡∏≤‡∏¢‡πÑ‡∏ï‡∏£‡∏°‡∏≤‡∏™", "‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô"], index=0)
# =========================
# 6) ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• (Main Processing Logic)
# =========================
df_main = pd.DataFrame()
processed_data_loaded = False
if not up and Path(PERSISTED_DATA_PATH).is_file():
    try:
        df_main = pd.read_parquet(PERSISTED_DATA_PATH); df_main['Occurrence Date'] = pd.to_datetime(df_main['Occurrence Date'])
        processed_data_loaded = True
        df_main = add_time_parts_fiscal(df_main)
    except Exception as e:
        st.sidebar.error(f"‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏î‡∏¥‡∏° ({PERSISTED_DATA_PATH.name}) ‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
        df_main = pd.DataFrame()
if not processed_data_loaded and up is not None:
    try:
        raw_df = read_uploaded_table(up)
        with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå..."):
            df_main = massage_schema(raw_df); df_main = add_time_parts_fiscal(df_main)
            try:
                df_main.to_parquet(PERSISTED_DATA_PATH, index=False)
            except Exception as e:
                st.sidebar.error(f"‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ({PERSISTED_DATA_PATH.name}) ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")
    except Exception as e:
        st.error(f"‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• '{up.name}' ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")
        df_main = pd.DataFrame()

if df_main.empty:
    st.info("üëà ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
    st.stop()

# --- Apply Filters selected in Sidebar ---
fy_opts = ["-- ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î --"] + sorted(df_main['FY_int'].astype(str).unique().tolist()) if 'FY_int' in df_main else ["-- ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î --"]
month_order = [10, 11, 12] + list(range(1, 10))
month_opts = ["-- ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î --"] + [f"{m:02d}-{TH_MONTH_TINY.get(m, '?')}" for m in month_order] if 'Month_int' in df_main else ["-- ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î --"]

with st.sidebar:
    sel_fy = None; sel_fq = None; sel_month_num = None
    if period_mode == "‡∏£‡∏≤‡∏¢‡∏õ‡∏µ":
        sel_fy = st.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏õ‡∏µ‡∏á‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì", fy_opts, index=0)
    elif period_mode == "‡∏£‡∏≤‡∏¢‡πÑ‡∏ï‡∏£‡∏°‡∏≤‡∏™":
        c1, c2 = st.columns(2)
        with c1: sel_fy = st.selectbox("‡∏õ‡∏µ‡∏á‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì", fy_opts, index=0, key="fq_year")
        with c2: sel_fq = st.selectbox("‡πÑ‡∏ï‡∏£‡∏°‡∏≤‡∏™", ["-- ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î --", "Q1", "Q2", "Q3", "Q4"], index=0, key="fq_quarter")
    elif period_mode == "‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô":
        c1, c2 = st.columns(2)
        with c1: sel_fy = st.selectbox("‡∏õ‡∏µ‡∏á‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì", fy_opts, index=0, key="fm_year")
        with c2:
            month_label_select = st.selectbox("‡πÄ‡∏î‡∏∑‡∏≠‡∏ô", month_opts, index=0, key="fm_month")
            if month_label_select not in (None, "", "-- ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î --"):
                sel_month_num = int(month_label_select.split("-")[0])

df_time = filter_by_period_fiscal(df_main, period_mode, fy=sel_fy, fq=sel_fq, m=sel_month_num)
filtered = filter_by_group_and_unit(df_time, sel_group, sel_unit)

# --- Update Sidebar Stats ---
sidebar_stats_placeholder = st.sidebar.empty()
if filtered.empty:
    sidebar_stats_placeholder.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å")
else:
    min_date_filt = filtered['Occurrence Date'].min(); max_date_filt = filtered['Occurrence Date'].max()
    min_date_str_filt = min_date_filt.strftime('%d/%m/%Y') if pd.notna(min_date_filt) else "N/A"
    max_date_str_filt = max_date_filt.strftime('%d/%m/%Y') if pd.notna(max_date_filt) else "N/A"
    total_month_filt = 0
    if pd.notna(min_date_filt) and pd.notna(max_date_filt):
        max_p_filt = max_date_filt.to_period('M'); min_p_filt = min_date_filt.to_period('M')
        total_month_filt = max(1, (max_p_filt.year - min_p_filt.year) * 12 + (max_p_filt.month - min_p_filt.month) + 1)
    sidebar_stats_placeholder.markdown(f"**‡∏ä‡πà‡∏ß‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡∏Å‡∏£‡∏≠‡∏á):** {min_date_str_filt} ‡∏ñ‡∏∂‡∏á {max_date_str_filt}")
    sidebar_stats_placeholder.markdown(f"**‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô (‡∏Å‡∏£‡∏≠‡∏á):** {total_month_filt} ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô")
    sidebar_stats_placeholder.markdown(f"**‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå (‡∏Å‡∏£‡∏≠‡∏á‡πÅ‡∏•‡πâ‡∏ß):** {filtered.shape[0]:,} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
    app_functions_list = ["RCA Helpdesk (AI Assistant)"]
    st.sidebar.markdown("---");
    st.sidebar.markdown("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•:")

    dashboard_pages_list = ["‡πÅ‡∏î‡∏ä‡∏ö‡∏≠‡∏£‡πå‡∏î‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°", "Incidents Analysis","Risk Matrix (Interactive)","Risk level", "Risk Register Assistant", "Heatmap ‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô", "Sentinel Events & Top 10", "‡∏Å‡∏£‡∏≤‡∏ü‡∏™‡∏£‡∏∏‡∏õ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå (‡∏£‡∏≤‡∏¢‡∏°‡∏¥‡∏ï‡∏¥)", "‡∏™‡∏£‡∏∏‡∏õ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ï‡∏≤‡∏° Safety Goals", "Persistence Risk Index", "Early Warning: ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏™‡∏π‡∏á‡∏Ç‡∏∂‡πâ‡∏ô", "‡∏ö‡∏ó‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£"]
    if 'selected_analysis' not in st.session_state: st.session_state.selected_analysis = "‡πÅ‡∏î‡∏ä‡∏ö‡∏≠‡∏£‡πå‡∏î‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°"
    st.markdown("---")
    for option in app_functions_list:
        if st.sidebar.button(option, key=f"btn_{option}", type="primary" if st.session_state.selected_analysis == option else "secondary", use_container_width=True):
            st.session_state.selected_analysis = option; st.rerun()

    for option in dashboard_pages_list:
        if st.sidebar.button(option, key=f"btn_{option}", type="primary" if st.session_state.selected_analysis == option else "secondary", use_container_width=True):
            st.session_state.selected_analysis = option; st.rerun()

    # --- Sidebar Footer ---
    st.sidebar.markdown("---")
    st.sidebar.markdown(f"""
    **‡∏Å‡∏¥‡∏ï‡∏ï‡∏¥‡∏Å‡∏£‡∏£‡∏°‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®:** ‡∏Ç‡∏≠‡∏Ç‡∏≠‡∏ö‡∏û‡∏£‡∏∞‡∏Ñ‡∏∏‡∏ì 
    - Prof. Shin Ushiro
    - ‡∏ô‡∏û.‡∏≠‡∏ô‡∏∏‡∏ß‡∏±‡∏í‡∏ô‡πå ‡∏®‡∏∏‡∏†‡∏ä‡∏∏‡∏ï‡∏¥‡∏Å‡∏∏‡∏• 
    - ‡∏ô‡∏û.‡∏Å‡πâ‡∏≠‡∏á‡πÄ‡∏Å‡∏µ‡∏¢‡∏£‡∏ï‡∏¥ ‡πÄ‡∏Å‡∏©‡πÄ‡∏û‡πá‡∏ä‡∏£‡πå 
    - ‡∏û‡∏ç.‡∏õ‡∏¥‡∏¢‡∏ß‡∏£‡∏£‡∏ì ‡∏•‡∏¥‡πâ‡∏°‡∏õ‡∏±‡∏ç‡∏ç‡∏≤‡πÄ‡∏•‡∏¥‡∏® 
    - ‡∏†‡∏Å.‡∏õ‡∏£‡∏°‡∏¥‡∏ô‡∏ó‡∏£‡πå ‡∏ß‡∏µ‡∏£‡∏∞‡∏≠‡∏ô‡∏±‡∏ô‡∏ï‡∏ß‡∏±‡∏í‡∏ô‡πå    
    - ‡∏ú‡∏®.‡∏î‡∏£.‡∏ô‡∏¥‡πÄ‡∏ß‡∏®‡∏ô‡πå ‡∏Å‡∏∏‡∏•‡∏ß‡∏á‡∏Ñ‡πå (‡∏≠.‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤)

    ‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏π‡∏á ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏£‡∏¥‡πÄ‡∏£‡∏¥‡πà‡∏° ‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏ï‡πá‡∏° ‡∏™‡∏ô‡∏±‡∏ö‡∏™‡∏ô‡∏∏‡∏ô ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏£‡∏á‡∏ö‡∏±‡∏ô‡∏î‡∏≤‡∏•‡πÉ‡∏à ‡∏≠‡∏±‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ô‡∏µ‡πâ

    ‡πÅ‡∏•‡∏∞‡∏Ç‡∏≠‡∏Ç‡∏≠‡∏ö‡∏û‡∏£‡∏∞‡∏Ñ‡∏∏‡∏ì‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏ó‡∏∏‡∏Å‡πÅ‡∏´‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏π‡∏á ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏ô‡∏∏‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡πÄ‡∏≠‡∏∑‡πâ‡∏≠‡πÄ‡∏ü‡∏∑‡πâ‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏±‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏¢‡∏¥‡πà‡∏á‡∏ï‡πà‡∏≠‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏â‡∏ö‡∏±‡∏ö‡∏ô‡∏µ‡πâ ‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà:
    - ‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•‡∏ö‡∏∂‡∏á‡∏Å‡∏≤‡∏¨ ‡∏à.‡∏ö‡∏∂‡∏á‡∏Å‡∏≤‡∏¨
    - ‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à‡∏û‡∏£‡∏∞‡∏ç‡∏≤‡∏ì‡∏™‡∏±‡∏á‡∏ß‡∏£ ‡∏à.‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡∏£‡∏≤‡∏¢ 
    - ‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•‡∏™‡∏ß‡∏ô‡∏ú‡∏∂‡πâ‡∏á ‡∏à.‡∏£‡∏≤‡∏ä‡∏ö‡∏∏‡∏£‡∏µ
    - ‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•‡πÄ‡∏à‡πâ‡∏≤‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏û‡∏ö‡∏π‡∏•‡∏¢‡πå ‡∏û‡∏ô‡∏°‡∏ó‡∏ß‡∏ô ‡∏à.‡∏Å‡∏≤‡∏ç‡∏à‡∏ô‡∏ö‡∏∏‡∏£‡∏µ
    - ‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•‡∏ä‡∏∞‡∏≠‡∏ß‡∏î ‡∏à.‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏ò‡∏£‡∏£‡∏°‡∏£‡∏≤‡∏ä
    - ‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•‡∏≠‡∏∏‡∏ö‡∏•‡∏£‡∏±‡∏Å‡∏©‡πå ‡∏ò‡∏ô‡∏ö‡∏∏‡∏£‡∏µ ‡∏à.‡∏≠‡∏∏‡∏ö‡∏•‡∏£‡∏≤‡∏ä‡∏≤‡∏ô‡∏µ
    - ‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•‡πÄ‡∏Ç‡∏≤‡∏ä‡∏∞‡πÄ‡∏°‡∏≤‡πÄ‡∏â‡∏•‡∏¥‡∏°‡∏û‡∏£‡∏∞‡πÄ‡∏Å‡∏µ‡∏¢‡∏£‡∏ï‡∏¥ ‡πò‡πê ‡∏û‡∏£‡∏£‡∏©‡∏≤ ‡∏à.‡∏£‡∏∞‡∏¢‡∏≠‡∏á
    - ‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à‡∏û‡∏£‡∏∞‡∏¢‡∏∏‡∏û‡∏£‡∏≤‡∏ä‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡∏Ç‡∏≠‡∏á ‡∏à. ‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡∏£‡∏≤‡∏¢ 
    - Kyushu University Hospital, Fukuoka, Japan (‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏î‡∏π‡∏á‡∏≤‡∏ô)
    - ‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û ‡∏à‡∏±‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ, ‡∏à.‡∏à‡∏±‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ (‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏î‡∏π‡∏á‡∏≤‡∏ô)
    - ‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢‡πÅ‡∏°‡πà‡∏ü‡πâ‡∏≤‡∏´‡∏•‡∏ß‡∏á ‡∏à.‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡∏£‡∏≤‡∏¢ (‡∏ï‡πâ‡∏ô‡∏™‡∏±‡∏á‡∏Å‡∏±‡∏î)  
    """)  # <--- ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß (‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ä‡∏¥‡∏î‡∏ã‡πâ‡∏≤‡∏¢)

    st.sidebar.markdown("---")
    st.sidebar.markdown(
        '<p style="font-size:12px; color:gray;">*‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏Ç‡∏≠‡∏á‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏ô‡∏¥‡∏û‡∏ô‡∏ò‡πå IMPLEMENTING THE  HOSPITAL OCCURRENCE/INCIDENT ANALYSIS & RISK REGISTER (HOIA-RR TOOL) IN THAI HOSPITALS: A STUDY ON EFFECTIVE ADOPTION ‡πÇ‡∏î‡∏¢ ‡∏ô‡∏≤‡∏á‡∏™‡∏≤‡∏ß‡∏ß‡∏¥‡∏•‡∏≤‡∏®‡∏¥‡∏ô‡∏µ  ‡πÄ‡∏Ç‡∏∑‡πà‡∏≠‡∏ô‡πÅ‡∏Å‡πâ‡∏ß ‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏õ‡∏£‡∏¥‡∏ç‡∏ç‡∏≤‡πÇ‡∏ó ‡∏™‡∏≥‡∏ô‡∏±‡∏Å‡∏ß‡∏¥‡∏ä‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û ‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢‡πÅ‡∏°‡πà‡∏ü‡πâ‡∏≤‡∏´‡∏•‡∏ß‡∏á</p>',
        unsafe_allow_html=True)
# =========================
# 7) Helper / Stubs (‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢ ‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏´‡∏ô‡πâ‡∏≤‡∏≠‡∏∑‡πà‡∏ô‡∏û‡∏±‡∏á)
# =========================

# ========= ‡∏™‡∏µ/‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Risk Matrix (Global Helpers) =========
HEADER_TOPLEFT = "#E6F5FF";
HEADER_SIDE = "#F3C7B1";
HEADER_FREQ = "#EED0BE"
GREEN = "#00D26A";
YELLOW = "#FFE900";
ORANGE = "#FF9800";
RED = "#FF2D2D"
PALETTE_FROM_IMAGE = {
    "11": GREEN, "12": GREEN, "13": GREEN, "14": YELLOW, "15": YELLOW,
    "21": GREEN, "22": YELLOW, "23": YELLOW, "24": ORANGE, "25": ORANGE,
    "31": YELLOW, "32": YELLOW, "33": YELLOW, "34": ORANGE, "35": ORANGE,
    "41": ORANGE, "42": ORANGE, "43": RED, "44": RED, "45": RED,
    "51": RED, "52": RED, "53": RED, "54": RED, "55": RED,
}


def _text_color_for(bg_hex: str) -> str:
    h = bg_hex.lstrip("#");
    r, g, b = int(h[0:2], 16) / 255, int(h[2:4], 16) / 255, int(h[4:6], 16) / 255
    return "#000000" if (0.2126 * r + 0.7152 * g + 0.0722 * b) > 0.6 else "#FFFFFF"


# ========= ‡∏à‡∏ö‡∏™‡πà‡∏ß‡∏ô‡∏™‡∏µ Risk Matrix =========


def render_incidents_analysis(df: pd.DataFrame):
    st.markdown("<h4 style='color: #001f3f;'>Incidents Analysis</h4>", unsafe_allow_html=True)

    if 'Resulting Actions' not in df.columns or '‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç' not in df.columns:
        st.error(
            "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'Resulting Actions' ‡∏´‡∏£‡∏∑‡∏≠ '‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç' ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    else:
        tab_psg9, tab_groups, tab_by_code, tab_waitlist = st.tabs(
            ["üëÅÔ∏è ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ï‡∏≤‡∏°‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà PSG9",
             "üëÅÔ∏è ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ï‡∏≤‡∏°‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏´‡∏•‡∏±‡∏Å (C/G)",
             "üëÅÔ∏è ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏≤‡∏¢‡∏£‡∏´‡∏±‡∏™",
             "üëÅÔ∏è ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç(‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á)"])

        # --- Tab ‡∏ó‡∏µ‡πà 1: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ï‡∏≤‡∏°‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà PSG9 ---
        with tab_psg9:
            st.subheader("‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ï‡∏≤‡∏°‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢ (PSG9)")
            psg9_summary_table = create_psg9_summary_table(df)
            if psg9_summary_table is not None and not psg9_summary_table.empty:
                st.dataframe(psg9_summary_table, use_container_width=True)
            else:
                st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç 9 ‡∏Ç‡πâ‡∏≠‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏µ‡πâ")

            st.markdown("---")
            st.subheader("‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà PSG9")

            # (PSG9_label_dict ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ global ‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ß‡πâ‡∏ï‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÅ‡∏≠‡∏õ)
            psg9_categories = {k: v for k, v in PSG9_label_dict.items() if
                               v in df['‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç'].unique()}

            for psg9_id, psg9_name in psg9_categories.items():
                psg9_df = df[df['‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç'] == psg9_name]
                total_count = len(psg9_df)
                resolved_df = psg9_df[~psg9_df['Resulting Actions'].astype(str).isin(['None', '', 'nan'])]
                resolved_count = len(resolved_df)
                unresolved_count = total_count - resolved_count

                expander_title = f"{psg9_name} (‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {total_count} | ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß: {resolved_count} | ‡∏£‡∏≠‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: {unresolved_count})"
                with st.expander(expander_title):
                    c1, c2, c3 = st.columns(3)
                    c1.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", f"{total_count:,}")
                    c2.metric("‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß", f"{resolved_count:,}")
                    c3.metric("‡∏£‡∏≠‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç", f"{unresolved_count:,}")

                    if total_count > 0:
                        tab_resolved, tab_unresolved = st.tabs(
                            [f"‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß ({resolved_count})", f"‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç ({unresolved_count})"])
                        with tab_resolved:
                            if resolved_count > 0:
                                st.dataframe(
                                    resolved_df[['Occurrence Date', 'Incident', 'Impact', 'Resulting Actions']],
                                    hide_index=True, use_container_width=True, column_config={
                                        "Occurrence Date": st.column_config.DatetimeColumn("‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î",
                                                                                           format="DD/MM/YYYY")})
                            else:
                                st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏ô‡∏´‡∏°‡∏ß‡∏î‡∏ô‡∏µ‡πâ")
                        with tab_unresolved:
                            if unresolved_count > 0:
                                st.dataframe(
                                    psg9_df[psg9_df['Resulting Actions'].astype(str).isin(['None', '', 'nan'])][
                                        ['Occurrence Date', 'Incident', 'Impact', '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î_Anonymized']],
                                    hide_index=True, use_container_width=True, column_config={
                                        "Occurrence Date": st.column_config.DatetimeColumn("‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î",
                                                                                           format="DD/MM/YYYY")})
                            else:
                                st.success("‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏´‡∏°‡∏ß‡∏î‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß")

        # --- Tab ‡∏ó‡∏µ‡πà 2: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ï‡∏≤‡∏°‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏´‡∏•‡∏±‡∏Å (C/G) ---
        with tab_groups:
            # ------------------ ‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏≤‡∏á‡∏Ñ‡∏•‡∏¥‡∏ô‡∏¥‡∏Å (C) ------------------
            st.markdown("#### ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏≤‡∏á‡∏Ñ‡∏•‡∏¥‡∏ô‡∏¥‡∏Å (‡∏£‡∏´‡∏±‡∏™‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ C)")
            df_clinical = df[df['‡∏£‡∏´‡∏±‡∏™'].str.startswith('C', na=False)].copy()

            if df_clinical.empty:
                st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Å‡∏•‡∏∏‡πà‡∏° Clinical ‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏µ‡πâ")
            else:
                st.subheader("‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Å‡∏•‡∏∏‡πà‡∏° Clinical")
                clinical_summary_table = create_summary_table_by_category(df_clinical, '‡∏´‡∏°‡∏ß‡∏î')
                if not clinical_summary_table.empty:
                    st.dataframe(clinical_summary_table, use_container_width=True)
                else:
                    st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ")
                st.markdown("---")

                st.subheader("‡πÄ‡∏à‡∏≤‡∏∞‡∏•‡∏∂‡∏Å‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ï‡∏≤‡∏°‡∏´‡∏°‡∏ß‡∏î‡∏¢‡πà‡∏≠‡∏¢ (Clinical)")
                clinical_categories = sorted([cat for cat in df_clinical['‡∏´‡∏°‡∏ß‡∏î'].unique() if cat and pd.notna(cat)])
                for category in clinical_categories:
                    category_df = df_clinical[df_clinical['‡∏´‡∏°‡∏ß‡∏î'] == category]
                    total_count = len(category_df)
                    resolved_df = category_df[
                        ~category_df['Resulting Actions'].astype(str).isin(['None', '', 'nan'])]
                    resolved_count = len(resolved_df)
                    unresolved_count = total_count - resolved_count

                    expander_title = f"{category} (‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {total_count} | ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß: {resolved_count} | ‡∏£‡∏≠‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: {unresolved_count})"
                    with st.expander(expander_title):
                        tab_resolved, tab_unresolved = st.tabs(
                            [f"‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß ({resolved_count})", f"‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç ({unresolved_count})"])
                        with tab_resolved:
                            if resolved_count > 0:
                                st.dataframe(
                                    resolved_df[['Occurrence Date', 'Incident', 'Impact', 'Resulting Actions']],
                                    hide_index=True, use_container_width=True, column_config={
                                        "Occurrence Date": st.column_config.DatetimeColumn("‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î",
                                                                                           format="DD/MM/YYYY")})
                            else:
                                st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏ô‡∏´‡∏°‡∏ß‡∏î‡∏ô‡∏µ‡πâ")
                        with tab_unresolved:
                            if unresolved_count > 0:
                                st.dataframe(category_df[category_df['Resulting Actions'].astype(str).isin(
                                    ['None', '', 'nan'])][['Occurrence Date', 'Incident', 'Impact',
                                                           '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î_Anonymized']], hide_index=True,
                                             use_container_width=True, column_config={
                                        "Occurrence Date": st.column_config.DatetimeColumn("‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î",
                                                                                           format="DD/MM/YYYY")})
                            else:
                                st.success("‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏´‡∏°‡∏ß‡∏î‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß")

            st.markdown("---")

            # ------------------ ‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ (G) ------------------
            st.markdown("#### ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ (‡∏£‡∏´‡∏±‡∏™‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ G)")
            df_general = df[df['‡∏£‡∏´‡∏±‡∏™'].str.startswith('G', na=False)].copy()

            if df_general.empty:
                st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Å‡∏•‡∏∏‡πà‡∏° General ‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏µ‡πâ")
            else:
                st.subheader("‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Å‡∏•‡∏∏‡πà‡∏° General")
                general_summary_table = create_summary_table_by_category(df_general, '‡∏´‡∏°‡∏ß‡∏î')
                if not general_summary_table.empty:
                    st.dataframe(general_summary_table, use_container_width=True)
                else:
                    st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ")
                st.markdown("---")

                st.subheader("‡πÄ‡∏à‡∏≤‡∏∞‡∏•‡∏∂‡∏Å‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ï‡∏≤‡∏°‡∏´‡∏°‡∏ß‡∏î‡∏¢‡πà‡∏≠‡∏¢ (General)")
                general_categories = sorted([cat for cat in df_general['‡∏´‡∏°‡∏ß‡∏î'].unique() if cat and pd.notna(cat)])
                for category in general_categories:
                    category_df = df_general[df_general['‡∏´‡∏°‡∏ß‡∏î'] == category]
                    total_count = len(category_df)
                    resolved_df = category_df[
                        ~category_df['Resulting Actions'].astype(str).isin(['None', '', 'nan'])]
                    resolved_count = len(resolved_df)
                    unresolved_count = total_count - resolved_count

                    expander_title = f"{category} (‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {total_count} | ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß: {resolved_count} | ‡∏£‡∏≠‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: {unresolved_count})"
                    with st.expander(expander_title):
                        tab_resolved, tab_unresolved = st.tabs(
                            [f"‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß ({resolved_count})", f"‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç ({unresolved_count})"])
                        with tab_resolved:
                            if resolved_count > 0:
                                st.dataframe(
                                    resolved_df[['Occurrence Date', 'Incident', 'Impact', 'Resulting Actions']],
                                    hide_index=True, use_container_width=True, column_config={
                                        "Occurrence Date": st.column_config.DatetimeColumn("‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î",
                                                                                           format="DD/MM/YYYY")})
                            else:
                                st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏ô‡∏´‡∏°‡∏ß‡∏î‡∏ô‡∏µ‡πâ")
                        with tab_unresolved:
                            if unresolved_count > 0:
                                st.dataframe(category_df[category_df['Resulting Actions'].astype(str).isin(
                                    ['None', '', 'nan'])][['Occurrence Date', 'Incident', 'Impact',
                                                           '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î_Anonymized']], hide_index=True,
                                             use_container_width=True, column_config={
                                        "Occurrence Date": st.column_config.DatetimeColumn("‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î",
                                                                                           format="DD/MM/YYYY")})
                            else:
                                st.success("‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏´‡∏°‡∏ß‡∏î‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß")

        # --- Tab ‡∏ó‡∏µ‡πà 3: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏≤‡∏¢‡∏£‡∏´‡∏±‡∏™ ---
        with tab_by_code:
            st.subheader("‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏ï‡∏≤‡∏°‡∏£‡∏´‡∏±‡∏™")
            st.info(
                "‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏ï‡∏≤‡∏°‡∏£‡∏´‡∏±‡∏™ ‡πÅ‡∏•‡∏∞‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á (E-I) ‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢")

            summary_table_code = create_summary_table_by_code(df)

            if summary_table_code.empty:
                st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏£‡∏≤‡∏¢‡∏£‡∏´‡∏±‡∏™")
            else:
                st.markdown("##### ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏£‡∏≤‡∏¢‡∏£‡∏´‡∏±‡∏™")
                st.dataframe(summary_table_code, use_container_width=True)
                st.markdown("---")

                st.markdown("##### ‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏™‡∏î‡∏á‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á (‡∏£‡∏∞‡∏î‡∏±‡∏ö E-I) ‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢")
                chart_data = summary_table_code[summary_table_code['‡∏£‡∏ß‡∏° E-up'] > 0].copy()

                if chart_data.empty:
                    st.success("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á (E-I) ‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å")
                else:
                    top_n_chart = st.slider(
                        "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏´‡∏±‡∏™‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ö‡∏ô‡∏Å‡∏£‡∏≤‡∏ü:", min_value=1,
                        max_value=min(30, len(chart_data)), value=min(15, len(chart_data)),
                        step=1, key="top_n_chart_slider_tab"
                    )
                    top_chart_data = chart_data.nlargest(top_n_chart, '‡∏£‡∏ß‡∏° E-up')
                    fig = px.bar(
                        top_chart_data.sort_values('‡∏£‡∏ß‡∏° E-up', ascending=True),
                        x='‡∏£‡∏ß‡∏° E-up', y=top_chart_data.index, orientation='h',
                        title=f'Top {top_n_chart} ‡∏£‡∏´‡∏±‡∏™‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏™‡∏π‡∏á (E-I) ‡∏™‡∏∞‡∏™‡∏°',
                        labels={'‡∏£‡∏ß‡∏° E-up': '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏™‡∏∞‡∏™‡∏° (E-I)', 'y': '‡∏£‡∏´‡∏±‡∏™‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå'},
                        text='‡∏£‡∏ß‡∏° E-up', color='‡∏£‡∏ß‡∏° E-up', color_continuous_scale='Reds'
                    )
                    fig.update_layout(height=max(400, len(top_chart_data) * 25), yaxis_title=None,
                                      coloraxis_showscale=False)
                    fig.update_traces(textposition='outside')
                    st.plotly_chart(fig, use_container_width=True)

        # --- Tab ‡∏ó‡∏µ‡πà 4: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç ---
        with tab_waitlist:
            st.subheader("‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á (E-I & 3-5)")

            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏à‡∏≤‡∏Å 'df' ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤‡πÉ‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
            severe_impact_levels_list = ['3', '4', '5']
            severe_df = df[df['Impact Level'].isin(severe_impact_levels_list)].copy()
            total_severe_incidents = severe_df.shape[0]

            total_severe_psg9_incidents = severe_df[severe_df['‡∏£‡∏´‡∏±‡∏™'].isin(psg9_r_codes_for_counting)].shape[
                0] if psg9_r_codes_for_counting else 0

            total_severe_unresolved_incidents_val = 0
            total_severe_unresolved_psg9_incidents_val = 0

            if 'Resulting Actions' in df.columns:
                unresolved_severe_df = severe_df[severe_df['Resulting Actions'].astype(str).isin(['None', '', 'nan'])]
                total_severe_unresolved_incidents_val = unresolved_severe_df.shape[0]
                total_severe_unresolved_psg9_incidents_val = \
                unresolved_severe_df[unresolved_severe_df['‡∏£‡∏´‡∏±‡∏™'].isin(psg9_r_codes_for_counting)].shape[
                    0] if psg9_r_codes_for_counting else 0

            val_row3_total_pct = (
                    total_severe_unresolved_incidents_val / total_severe_incidents * 100) if total_severe_incidents > 0 else 0
            val_row3_psg9_pct = (
                    total_severe_unresolved_psg9_incidents_val / total_severe_psg9_incidents * 100) if total_severe_psg9_incidents > 0 else 0

            summary_action_data = [
                {"‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î": "1. ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á E-I & 3-5", "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î": f"{total_severe_incidents:,}",
                 "‡πÄ‡∏â‡∏û‡∏≤‡∏∞ PSG9": f"{total_severe_psg9_incidents:,}"},
                {"‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î": "2. ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå E-I & 3-5 ‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç",
                 "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î": f"{total_severe_unresolved_incidents_val:,}",
                 "‡πÄ‡∏â‡∏û‡∏≤‡∏∞ PSG9": f"{total_severe_unresolved_psg9_incidents_val:,}"},
                {"‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î": "3. % ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå E-I & 3-5 ‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç",
                 "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î": f"{val_row3_total_pct:.2f}%", "‡πÄ‡∏â‡∏û‡∏≤‡∏∞ PSG9": f"{val_row3_psg9_pct:.2f}%"}
            ]
            st.dataframe(pd.DataFrame(summary_action_data).set_index('‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î'), use_container_width=True)

            st.subheader("‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç (‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á)")
            unresolved_df = df[df['Resulting Actions'].astype(str).isin(['None', '', 'nan'])].copy()

            if unresolved_df.empty:
                st.success("üéâ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏µ‡πâ ‡∏¢‡∏≠‡∏î‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°‡∏°‡∏≤‡∏Å‡∏Ñ‡∏£‡∏±‡∏ö!")
            else:
                st.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", f"{len(unresolved_df):,} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
                severity_order = ['Critical', 'High', 'Medium', 'Low', 'Undefined']
                for severity in severity_order:
                    severity_df = unresolved_df[unresolved_df['Category Color'] == severity]
                    if not severity_df.empty:
                        with st.expander(f"‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á: {severity} ({len(severity_df)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)"):
                            display_cols = ['Occurrence Date', 'Incident', 'Impact',
                                            '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î_Anonymized']

                            st.dataframe(severity_df[display_cols], use_container_width=True, hide_index=True,
                                         column_config={"Occurrence Date": st.column_config.DatetimeColumn("‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î",
                                                                                                           format="DD/MM/YYYY")})


def render_risk_matrix_interactive(df: pd.DataFrame, key_prefix: str = "main_rmx"):
    st.subheader("Risk Matrix (Interactive)")
    impact_level_keys = ['5', '4', '3', '2', '1'];
    freq_level_keys = ['1', '2', '3', '4', '5']
    matrix_df = df[
        df['Impact Level'].astype(str).isin(impact_level_keys) &
        df['Frequency Level'].astype(str).isin(freq_level_keys)
        ].copy()
    matrix_data_counts = np.zeros((5, 5), dtype=int)
    if not matrix_df.empty:
        risk_counts_df = matrix_df.groupby(['Impact Level', 'Frequency Level']).size().reset_index(name='counts')
        for _, row in risk_counts_df.iterrows():
            r = impact_level_keys.index(str(row['Impact Level']))
            c = freq_level_keys.index(str(row['Frequency Level']))
            matrix_data_counts[r, c] = int(row['counts'])

    impact_labels_display = {
        '5': "I / 5<br>Extreme / Death", '4': "G-H / 4<br>Major / Severe", '3': "E-F / 3<br>Moderate",
        '2': "C-D / 2<br>Minor / Low", '1': "A-B / 1<br>Insignificant / No Harm",
    }
    freq_labels_display_short = {"1": "F1", "2": "F2", "3": "F3", "4": "F4", "5": "F5"}
    freq_labels_display_long = {
        "1": "Remote<br>(<2/mth)", "2": "Uncommon<br>(2-3/mth)", "3": "Occasional<br>(4-6/mth)",
        "4": "Probable<br>(7-29/mth)", "5": "Frequent<br>(>=30/mth)",
    }

    cols_header = st.columns([2.2, 1, 1, 1, 1, 1])
    with cols_header[0]:
        st.markdown(
            f"<div style='background-color:{HEADER_TOPLEFT}; color:{_text_color_for(HEADER_TOPLEFT)}; "
            f"padding:8px; text-align:center; font-weight:bold; border-radius:3px; margin:1px; height:60px; "
            f"display:flex; align-itemsV:center; justify-content:center;'>Impact / Frequency</div>",
            unsafe_allow_html=True
        )
    for i, fl in enumerate(freq_level_keys):
        with cols_header[i + 1]:
            st.markdown(
                f"<div style='background-color:{HEADER_FREQ}; color:{_text_color_for(HEADER_FREQ)}; "
                f"padding:8px; text-align:center; font-weight:bold; border-radius:3px; margin:1px; height:60px; "
                f"display:flex; flex-direction:column; align-items:center; justify-content:center;'>"
                f"<div>{freq_labels_display_short[fl]}</div>"
                f"<div style='font-size:0.7em;'>{freq_labels_display_long[fl]}</div></div>",
                unsafe_allow_html=True
            )
    for r, il in enumerate(impact_level_keys):
        row_cols = st.columns([2.2, 1, 1, 1, 1, 1])
        with row_cols[0]:
            st.markdown(
                f"<div style='background-color:{HEADER_SIDE}; color:{_text_color_for(HEADER_SIDE)}; "
                f"padding:8px; text-align:center; font-weight:bold; border-radius:3px; margin:1px; height:70px; "
                f"display:flex; align-items:center; justify-content:center;'>{impact_labels_display[il]}</div>",
                unsafe_allow_html=True
            )
        for c, fl in enumerate(freq_level_keys):
            with row_cols[c + 1]:
                code = f'{il}{fl}'
                cell_bg = PALETTE_FROM_IMAGE.get(code, "#808080")
                cnt = int(matrix_data_counts[r, c])
                st.markdown(
                    f"<div style='background-color:{cell_bg}; color:{_text_color_for(cell_bg)}; "
                    f"padding:5px; margin:1px; border-radius:3px; text-align:center; font-weight:bold; "
                    f"min-height:40px; display:flex; align-items:center; justify-content:center;'>{cnt}</div>",
                    unsafe_allow_html=True
                )
                if cnt > 0:
                    if st.button("üëÅÔ∏è", key=f"{key_prefix}_view_{code}", help=f"‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ - {cnt} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£",
                                 use_container_width=True):
                        st.session_state[f"{key_prefix}_il"] = il
                        st.session_state[f"{key_prefix}_fl"] = fl
                        st.session_state[f"{key_prefix}_show"] = True
                        st.rerun()
                else:
                    st.markdown("<div style='height:38px; margin-top:5px;'></div>", unsafe_allow_html=True)

    if st.session_state.get(f"{key_prefix}_show", False):
        il_selected = st.session_state.get(f"{key_prefix}_il")
        fl_selected = st.session_state.get(f"{key_prefix}_fl")
        df_incidents = df[
            (df['Impact Level'].astype(str) == str(il_selected)) &
            (df['Frequency Level'].astype(str) == str(fl_selected))
            ].copy()
        disp_cols_default = ['‡∏£‡∏´‡∏±‡∏™', '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á', 'Impact Level', 'Frequency Level', 'Risk Level',
                             'Occurrence Date', '‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô', '‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô']
        display_cols = [c for c in disp_cols_default if c in df_incidents.columns]
        with st.expander(
                f"‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå: Impact {il_selected} √ó Frequency {fl_selected} ‚Äì {len(df_incidents)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£",
                expanded=True):
            st.dataframe(df_incidents[display_cols], use_container_width=True, hide_index=True)
            if st.button("‡∏õ‡∏¥‡∏î‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£", key=f"{key_prefix}_close"):
                st.session_state[f"{key_prefix}_show"] = False
                st.session_state[f"{key_prefix}_il"] = None
                st.session_state[f"{key_prefix}_fl"] = None
                st.rerun()


def render_risk_level_summary(df: pd.DataFrame):
    st.subheader("‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏µ‡∏ï‡∏≤‡∏°‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå")
    st.info("‡∏™‡∏µ‡πÅ‡∏•‡∏∞‡∏õ‡πâ‡∏≤‡∏¢‡∏Å‡∏≥‡∏Å‡∏±‡∏ö (I: Impact, F: Frequency) ‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡∏ä‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ô‡∏±‡πâ‡∏ô‡πÜ")

    required = {'Impact Level', 'Frequency Level', '‡∏£‡∏´‡∏±‡∏™', '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á'}
    if not required.issubset(df.columns):
        st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô ('Impact Level','Frequency Level','‡∏£‡∏´‡∏±‡∏™','‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á')")
        return

    order = {'1': 1, '2': 2, '3': 3, '4': 4, '5': 5}
    tmp = df.copy()
    tmp['I_num'] = tmp['Impact Level'].map(order).fillna(0).astype(int)
    tmp['F_num'] = tmp['Frequency Level'].map(order).fillna(0).astype(int)
    tmp['score'] = tmp['I_num'] * 10 + tmp['F_num']  # ‡πÉ‡∏´‡πâ Impact ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Å‡∏ß‡πà‡∏≤

    idx = tmp.groupby(['‡∏£‡∏´‡∏±‡∏™', '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á'])['score'].idxmax()
    incident_risk_summary = (
        tmp.loc[idx, ['‡∏£‡∏´‡∏±‡∏™', '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á', 'Impact Level', 'Frequency Level', 'Incident Rate/mth']]
        .rename(columns={'Impact Level': 'max_impact_level',
                         'Frequency Level': 'frequency_level',
                         'Incident Rate/mth': 'total_occurrences'})
    )

    # ‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô _text_color_for() ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏ô‡∏¥‡∏¢‡∏≤‡∏°‡πÑ‡∏ß‡πâ‡∏Ç‡πâ‡∏≤‡∏á‡∏ö‡∏ô
    incident_risk_summary['risk_color_hex'] = incident_risk_summary.apply(
        lambda r: PALETTE_FROM_IMAGE.get(f"{str(r['max_impact_level'])}{str(r['frequency_level'])}", "#808080"), axis=1
    )
    if 'total_occurrences' in incident_risk_summary.columns:
        incident_risk_summary = incident_risk_summary.sort_values('total_occurrences', ascending=False)

    for _, row in incident_risk_summary.iterrows():
        color = row['risk_color_hex'];
        text_color = _text_color_for(color)
        risk_label = f"I: {row['max_impact_level']} | F: {row['frequency_level']}"
        c1, c2 = st.columns([1, 6])
        with c1:
            st.markdown(
                f'<div style="background-color:{color}; color:{text_color}; font-weight:bold; '
                f'text-align:center; padding:8px; border-radius:6px; height:100%; '
                f'display:flex; align-items:center; justify-content:center;">{risk_label}</div>',
                unsafe_allow_html=True
            )
        with c2:
            tot = row.get('total_occurrences', 0)
            st.markdown(f"**{row['‡∏£‡∏´‡∏±‡∏™']} | {row['‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á']}** "
                        f"(‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î: {float(tot):.2f} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)")


# --- START: Helper Functions for Incident Analysis ---

def create_psg9_summary_table(input_df):
    if not isinstance(input_df,
                      pd.DataFrame) or '‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç' not in input_df.columns or 'Impact' not in input_df.columns: return None
    psg9_placeholders = ["‡πÑ‡∏°‡πà‡∏à‡∏±‡∏î‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô PSG9 Catalog", "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏ (Merge PSG9 ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß)",
                         "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏ (‡πÄ‡∏ä‡πá‡∏Ñ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏ô PSG9code.xlsx)",
                         "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏ (PSG9code.xlsx ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÇ‡∏´‡∏•‡∏î/‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤)",
                         "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏ (Merge PSG9 ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß - rename)", "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏ (Merge PSG9 ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß - no col)",
                         "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏ (PSG9code.xlsx ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÇ‡∏´‡∏•‡∏î/‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô)"]
    df_filtered = input_df[
        ~input_df['‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç'].isin(psg9_placeholders) & input_df['‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç'].notna()].copy()
    if df_filtered.empty: return pd.DataFrame()
    try:
        summary_table = pd.crosstab(df_filtered['‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç'], df_filtered['Impact'], margins=True,
                                    margins_name='‡∏£‡∏ß‡∏° A-I')
    except Exception:
        return pd.DataFrame()
    if '‡∏£‡∏ß‡∏° A-I' in summary_table.index: summary_table = summary_table.drop(index='‡∏£‡∏ß‡∏° A-I')
    if summary_table.empty: return pd.DataFrame()
    all_impacts, e_up_impacts = list('ABCDEFGHI'), list('EFGHI')
    for impact_col in all_impacts:
        if impact_col not in summary_table.columns: summary_table[impact_col] = 0
    if '‡∏£‡∏ß‡∏° A-I' not in summary_table.columns: summary_table['‡∏£‡∏ß‡∏° A-I'] = summary_table[
        [col for col in all_impacts if col in summary_table.columns]].sum(axis=1)
    summary_table['‡∏£‡∏ß‡∏° E-up'] = summary_table[[col for col in e_up_impacts if col in summary_table.columns]].sum(axis=1)
    summary_table['‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞ E-up'] = (summary_table['‡∏£‡∏ß‡∏° E-up'] / summary_table['‡∏£‡∏ß‡∏° A-I'] * 100).fillna(0)
    # (PSG9_label_dict ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ global ‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ß‡πâ‡∏ï‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÅ‡∏≠‡∏õ)
    psg_order = [PSG9_label_dict[i] for i in sorted(PSG9_label_dict.keys()) if i in PSG9_label_dict]
    summary_table = summary_table.reindex(psg_order).fillna(0)
    display_cols_order = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', '‡∏£‡∏ß‡∏° E-up', '‡∏£‡∏ß‡∏° A-I', '‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞ E-up']
    final_table = summary_table[[col for col in display_cols_order if col in summary_table.columns]].copy()
    for col in final_table.columns:
        if col != '‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞ E-up': final_table[col] = final_table[col].astype(int)
    final_table['‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞ E-up'] = final_table['‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞ E-up'].map('{:.2f}%'.format)
    return final_table


def create_summary_table_by_code(dataframe):
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ï‡∏≤‡∏° '‡∏£‡∏´‡∏±‡∏™' ‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á
    ‡πÇ‡∏î‡∏¢‡πÉ‡∏ô‡πÅ‡∏ñ‡∏ß‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏£‡∏´‡∏±‡∏™‡πÅ‡∏•‡∏∞‡∏ä‡∏∑‡πà‡∏≠‡∏Ç‡∏≠‡∏á‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå
    """
    required_cols = ['‡∏£‡∏´‡∏±‡∏™', '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á', 'Impact']
    if not all(col in dataframe.columns for col in required_cols):
        missing_cols = [col for col in required_cols if col not in dataframe.columns]
        st.warning(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÑ‡∏î‡πâ ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡∏≤‡∏î‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå: {', '.join(missing_cols)}")
        return pd.DataFrame()

    df_copy = dataframe.copy()
    df_copy['‡∏£‡∏´‡∏±‡∏™ | ‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå'] = df_copy['‡∏£‡∏´‡∏±‡∏™'].astype(str) + " | " + df_copy[
        '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á'].fillna('')
    df_valid = df_copy.dropna(subset=['‡∏£‡∏´‡∏±‡∏™ | ‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå', 'Impact'])
    if df_valid.empty:
        return pd.DataFrame()

    summary = pd.crosstab(df_valid['‡∏£‡∏´‡∏±‡∏™ | ‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå'], df_valid['Impact'])
    severity_levels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I']
    summary = summary.reindex(columns=severity_levels, fill_value=0)
    e_to_i_cols = [col for col in ['E', 'F', 'G', 'H', 'I'] if col in summary.columns]
    summary['‡∏£‡∏ß‡∏° E-up'] = summary[e_to_i_cols].sum(axis=1)
    total_e_up_incidents = summary['‡∏£‡∏ß‡∏° E-up'].sum()

    if total_e_up_incidents > 0:
        summary['‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞ E-up'] = (summary['‡∏£‡∏ß‡∏° E-up'] / total_e_up_incidents * 100).map('{:.2f}%'.format)
    else:
        summary['‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞ E-up'] = '0.00%'

    summary = summary[summary.drop(columns=['‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞ E-up']).sum(axis=1) > 0]
    summary.index.name = "‡∏£‡∏´‡∏±‡∏™ | ‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå"
    return summary


def create_summary_table_by_category(dataframe, category_column_name):
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ï‡∏≤‡∏°‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á
    """
    if category_column_name not in dataframe.columns or 'Impact' not in dataframe.columns:
        st.error(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '{category_column_name}' ‡∏´‡∏£‡∏∑‡∏≠ 'Impact' ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
        return pd.DataFrame()

    df_valid = dataframe.dropna(subset=[category_column_name, 'Impact'])
    if df_valid.empty:
        return pd.DataFrame()

    summary = pd.crosstab(df_valid[category_column_name], df_valid['Impact'])
    severity_levels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I']
    summary = summary.reindex(columns=severity_levels, fill_value=0)
    e_to_i_cols = [col for col in ['E', 'F', 'G', 'H', 'I'] if col in summary.columns]
    summary['‡∏£‡∏ß‡∏° E-up'] = summary[e_to_i_cols].sum(axis=1)
    total_e_up_incidents = summary['‡∏£‡∏ß‡∏° E-up'].sum()

    if total_e_up_incidents > 0:
        summary['‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞ E-up'] = (summary['‡∏£‡∏ß‡∏° E-up'] / total_e_up_incidents * 100).map('{:.2f}%'.format)
    else:
        summary['‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞ E-up'] = '0.00%'

    summary.index.name = "‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà"
    return summary


# --- END: Helper Functions for Incident Analysis ---


def create_goal_summary_table(data_df_goal: pd.DataFrame, goal_category_name_param: str,
                              e_up_non_numeric_levels_param=None,
                              e_up_numeric_levels_param=None,
                              is_org_safety_table: bool = False) -> pd.DataFrame:
    """
    ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏á‡πà‡∏≤‡∏¢: ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà '‡∏´‡∏°‡∏ß‡∏î' ‡∏°‡∏µ‡∏Ñ‡∏≥‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏Å‡πà‡∏≠‡∏ô colon (P/S/O)
    ‡πÅ‡∏•‡πâ‡∏ß‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ï‡πà‡∏≠‡∏£‡∏´‡∏±‡∏™
    """
    if data_df_goal.empty or '‡∏´‡∏°‡∏ß‡∏î' not in data_df_goal.columns: return pd.DataFrame()
    key = goal_category_name_param.split(":")[0].strip()  # "P" / "S" / "O"
    sub = data_df_goal[data_df_goal['‡∏´‡∏°‡∏ß‡∏î'].astype(str).str.startswith(key, na=False)].copy()
    if sub.empty: return pd.DataFrame()
    cnt = sub['‡∏£‡∏´‡∏±‡∏™'].value_counts().reset_index()
    cnt.columns = ['‡∏£‡∏´‡∏±‡∏™', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô']
    if '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á' in sub.columns:
        names = sub[['‡∏£‡∏´‡∏±‡∏™', '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á']].drop_duplicates()
        cnt = cnt.merge(names, on='‡∏£‡∏´‡∏±‡∏™', how='left')
        cnt = cnt[['‡∏£‡∏´‡∏±‡∏™', '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô']]
    return cnt


@st.cache_data
def calculate_persistence_risk_score(_df: pd.DataFrame, total_months: int):
    risk_level_map_to_score = {"51": 21, "52": 22, "53": 23, "54": 24, "55": 25, "41": 16, "42": 17, "43": 18, "44": 19,
                               "45": 20, "31": 11, "32": 12, "33": 13, "34": 14, "35": 15, "21": 6, "22": 7, "23": 8,
                               "24": 9, "25": 10, "11": 1, "12": 2, "13": 3, "14": 4, "15": 5}
    if _df.empty or '‡∏£‡∏´‡∏±‡∏™' not in _df.columns or 'Risk Level' not in _df.columns: return pd.DataFrame()
    analysis_df = _df[['‡∏£‡∏´‡∏±‡∏™', '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á', 'Risk Level']].copy()
    analysis_df['Ordinal_Risk_Score'] = analysis_df['Risk Level'].astype(str).map(risk_level_map_to_score)
    analysis_df.dropna(subset=['Ordinal_Risk_Score'], inplace=True)
    if analysis_df.empty: return pd.DataFrame()
    persistence_metrics = analysis_df.groupby('‡∏£‡∏´‡∏±‡∏™').agg(Average_Ordinal_Risk_Score=('Ordinal_Risk_Score', 'mean'),
                                                          Total_Occurrences=('‡∏£‡∏´‡∏±‡∏™', 'size')).reset_index()
    total_months = max(1, total_months)
    persistence_metrics['Incident_Rate_Per_Month'] = persistence_metrics['Total_Occurrences'] / total_months
    max_rate = max(1, persistence_metrics['Incident_Rate_Per_Month'].max()) if not persistence_metrics.empty else 1
    persistence_metrics['Frequency_Score'] = persistence_metrics['Incident_Rate_Per_Month'] / max_rate
    persistence_metrics['Avg_Severity_Score'] = persistence_metrics['Average_Ordinal_Risk_Score'] / 25.0
    persistence_metrics['Persistence_Risk_Score'] = persistence_metrics['Frequency_Score'] + persistence_metrics[
        'Avg_Severity_Score']
    incident_names = _df[['‡∏£‡∏´‡∏±‡∏™', '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á']].drop_duplicates()
    final_df = pd.merge(persistence_metrics, incident_names, on='‡∏£‡∏´‡∏±‡∏™', how='left')
    return final_df.sort_values(by='Persistence_Risk_Score', ascending=False)


def prioritize_incidents_nb_logit_v2(_df: pd.DataFrame, horizon: int = 3,
                                     w_freq: float = 0.34, w_sev: float = 0.33, w_trend: float = 0.33) -> pd.DataFrame:
    # Stub ‡∏á‡πà‡∏≤‡∏¢: ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á + ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢
    if _df.empty: return pd.DataFrame()
    tmp = _df.copy()
    tmp['RiskScore'] = tmp['Risk Level'].map(lambda x: int(x) if str(x).isdigit() else 0)
    agg = tmp.groupby(['‡∏£‡∏´‡∏±‡∏™', '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á']).agg(
        total=('‡∏£‡∏´‡∏±‡∏™', 'size'),
        avg_risk=('RiskScore', 'mean')
    ).reset_index()
    agg['score'] = w_freq * (agg['total'] / max(1, agg['total'].max())) + w_sev * (
                agg['avg_risk'] / max(1, agg['avg_risk'].max()))
    return agg.sort_values('score', ascending=False)

# =========================
# 8) MAIN DISPLAY AREA
# =========================
selected_page = st.session_state.get('selected_analysis', "‡πÅ‡∏î‡∏ä‡∏ö‡∏≠‡∏£‡πå‡∏î‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°")

if selected_page == "RCA Helpdesk (AI Assistant)":
    st.markdown("<h4 style='color: #001f3f;'>AI Assistant: ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡πÄ‡∏Ñ‡∏™‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå</h4>", unsafe_allow_html=True)
    AI_IS_CONFIGURED = False
    if genai:
        api_key = os.environ.get("GOOGLE_API_KEY")
        if api_key:
            try:
                genai.configure(api_key=api_key); AI_IS_CONFIGURED = True
            except Exception as e:
                st.error(f"‚ö†Ô∏è ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ AI ‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
        else:
            st.error("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö GOOGLE_API_KEY")
        if not AI_IS_CONFIGURED:
            st.warning("AI ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤")

    if AI_IS_CONFIGURED:
        st.info("‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏Ñ‡∏™‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤ (‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏ï‡∏±‡∏ß‡∏ï‡∏ô‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢)")
        incident_description = st.text_area("‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå", height=150, key="rca_incident_input")
        if st.button("‡∏Ç‡∏≠‡∏Ñ‡∏≥‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤ AI", type="primary", use_container_width=True):
            if not incident_description.strip():
                st.warning("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏õ‡πâ‡∏≠‡∏ô‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î")
            else:
                with st.spinner("AI ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå..."):
                    consultation = get_consultation_response(incident_description)
                    st.markdown("--- \n ### ‡∏ú‡∏•‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤ AI:")
                    st.markdown(consultation)
    else:
        st.info("AI Assistant ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")

elif selected_page == "‡πÅ‡∏î‡∏ä‡∏ö‡∏≠‡∏£‡πå‡∏î‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°":
    st.markdown("<h4 style='color: #001f3f;'>‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå:</h4>", unsafe_allow_html=True)
    if filtered.empty:
        st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á")
    else:

        # --- START: ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÇ‡∏Ñ‡πâ‡∏î‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏ä‡πà‡∏ß‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ---
        min_date_filt = filtered['Occurrence Date'].min(); max_date_filt = filtered['Occurrence Date'].max()
        min_date_str = min_date_filt.strftime('%d/%m/%Y') if pd.notna(min_date_filt) else "N/A"
        max_date_str = max_date_filt.strftime('%d/%m/%Y') if pd.notna(max_date_filt) else "N/A"
        total_month = 0
        if pd.notna(min_date_filt) and pd.notna(max_date_filt):
            max_p_filt = max_date_filt.to_period('M'); min_p_filt = min_date_filt.to_period('M')
            total_month = max(1, (max_p_filt.year - min_p_filt.year) * 12 + (max_p_filt.month - min_p_filt.month) + 1)

        st.markdown(f"**‡∏ä‡πà‡∏ß‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå:** {min_date_str} ‡∏ñ‡∏∂‡∏á {max_date_str} (‡∏£‡∏ß‡∏° {total_month} ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)")
        st.markdown("---") # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏™‡πâ‡∏ô‡∏Ñ‡∏±‡πà‡∏ô
        # --- END: ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÇ‡∏Ñ‡πâ‡∏î ---

        cA, cB, cC, cD, cE = st.columns(5)
        # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå (‡πÅ‡∏ñ‡∏ß)
        cA.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå (‡πÅ‡∏ñ‡∏ß)", f"{len(filtered):,}")
        # ‡∏ä‡∏ô‡∏¥‡∏î‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå (Incident)
        incident_unique = filtered['Incident'].nunique() if 'Incident' in filtered.columns else 0
        cB.metric("‡∏ä‡∏ô‡∏¥‡∏î‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå (Incident)", f"{incident_unique:,}")
        # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô
        unit_unique = filtered[REF_COL].nunique() if REF_COL in filtered.columns else 0
        cC.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô", f"{unit_unique:,}")
        # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô
        group_unique = filtered['‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô'].nunique() if '‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô' in filtered.columns else 0
        cD.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô", f"{group_unique:,}")

        # --- ‡πÄ‡∏û‡∏¥‡πà‡∏° Metric ‡πÉ‡∏´‡∏°‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Self-Report ---
        if 'self_report' in filtered.columns:
            total_self_reports = int(filtered['self_report'].sum())
            cE.metric("Self-Reports (‡∏ô‡∏±‡∏ö 1)", f"{total_self_reports:,}")
        else:
            cE.metric("Self-Reports", "N/A")
        st.markdown("#### ‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ï‡πà‡∏≠‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô")
        if '‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô' in filtered.columns and not filtered['‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô'].isna().all():
            group_counts = (
                filtered
                .groupby("‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô", observed=True)
                .size()
                .reset_index(name="‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå")
                .sort_values("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå", ascending=False)
            )
            st.dataframe(group_counts, use_container_width=True)
        else:
            st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô' ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")

            # --- START: ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ Self-Report ---
        st.markdown("---")  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏™‡πâ‡∏ô‡∏Ñ‡∏±‡πà‡∏ô

        # 1. ‡∏™‡∏£‡∏∏‡∏õ‡∏ï‡∏≤‡∏°‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô
        st.markdown("#### Self-Report ‡∏ï‡πà‡∏≠‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô")
        if 'self_report' in filtered.columns and filtered['self_report'].sum() > 0:
            self_report_group_counts = (
                filtered.groupby("‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô", observed=True)['self_report']
                .sum()
                .reset_index(name="‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Self-Report")
                .astype({"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Self-Report": int})  # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏•‡∏Ç‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏ï‡πá‡∏°
            )
            # ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ report
            self_report_group_counts = self_report_group_counts[self_report_group_counts["‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Self-Report"] > 0]
            self_report_group_counts = self_report_group_counts.sort_values("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Self-Report", ascending=False)

            st.dataframe(self_report_group_counts, use_container_width=True, hide_index=True)
        else:
            st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Self-Report ‡πÉ‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å")

        # 2. ‡∏™‡∏£‡∏∏‡∏õ‡∏ï‡∏≤‡∏°‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô (REF_COL ‡∏Ñ‡∏∑‡∏≠ "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô")
        st.markdown("#### Self-Report ‡∏ï‡πà‡∏≠‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô (Top 20)")
        if 'self_report' in filtered.columns and filtered['self_report'].sum() > 0:
            self_report_unit_counts = (
                filtered.groupby(REF_COL, observed=True)['self_report']
                .sum()
                .reset_index(name="‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Self-Report")
                .astype({"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Self-Report": int})  # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏•‡∏Ç‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏ï‡πá‡∏°
            )
            # ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ report
            self_report_unit_counts = self_report_unit_counts[self_report_unit_counts["‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Self-Report"] > 0]
            self_report_unit_counts = self_report_unit_counts.sort_values("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Self-Report", ascending=False)

            # ‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏Ñ‡πà Top 20 ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏¢‡∏≤‡∏ß‡∏°‡∏≤‡∏Å
            st.dataframe(self_report_unit_counts.head(20), use_container_width=True, hide_index=True)
        else:
            st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Self-Report ‡πÉ‡∏ô‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å")
        # --- END: ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ Self-Report ---

    date_format_config = {"Occurrence Date": st.column_config.DatetimeColumn("‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î", format="DD/MM/YYYY HH:mm")}

    metrics_data_filt = {}
    metrics_data_filt['total_processed_incidents'] = filtered.shape[0]
    metrics_data_filt['total_psg9_incidents_for_metric1'] = filtered[filtered['‡∏£‡∏´‡∏±‡∏™'].isin(psg9_r_codes_for_counting)].shape[0] if psg9_r_codes_for_counting else 0

    if sentinel_composite_keys and '‡∏£‡∏´‡∏±‡∏™' in filtered.columns and 'Impact' in filtered.columns:
        filtered['Sentinel code for check'] = filtered['‡∏£‡∏´‡∏±‡∏™'].astype(str).str.strip() + '-' + filtered['Impact'].astype(str).str.strip()
        metrics_data_filt['total_sentinel_incidents_for_metric1'] = filtered[filtered['Sentinel code for check'].isin(sentinel_composite_keys)].shape[0]
    else:
        metrics_data_filt['total_sentinel_incidents_for_metric1'] = 0
        if 'Sentinel code for check' not in filtered.columns: filtered['Sentinel code for check'] = ""

        severe_impact_levels_list = ['3', '4', '5']
        df_severe_filt = filtered[filtered['Impact Level'].isin(severe_impact_levels_list)].copy()
        metrics_data_filt['total_severe_incidents'] = df_severe_filt.shape[0]
        if 'Resulting Actions' in filtered.columns:
            unresolved_filt = df_severe_filt[df_severe_filt['Resulting Actions'].astype(str).isin(['None', '', 'nan'])]
            metrics_data_filt['total_severe_unresolved_incidents_val'] = unresolved_filt.shape[0]
            metrics_data_filt['total_severe_unresolved_psg9_incidents_val'] = unresolved_filt[unresolved_filt['‡∏£‡∏´‡∏±‡∏™'].isin(psg9_r_codes_for_counting)].shape[0] if psg9_r_codes_for_counting else 0
        else:
            metrics_data_filt['total_severe_unresolved_incidents_val'] = "N/A"
            metrics_data_filt['total_severe_unresolved_psg9_incidents_val'] = "N/A"

        total_processed_incidents = metrics_data_filt.get("total_processed_incidents", 0)
        total_psg9_incidents_for_metric1 = metrics_data_filt.get("total_psg9_incidents_for_metric1", 0)
        total_sentinel_incidents_for_metric1 = metrics_data_filt.get("total_sentinel_incidents_for_metric1", 0)
        total_severe_incidents = metrics_data_filt.get("total_severe_incidents", 0)
        total_severe_unresolved_incidents_val = metrics_data_filt.get("total_severe_unresolved_incidents_val", "N/A")
        total_severe_unresolved_psg9_incidents_val = metrics_data_filt.get("total_severe_unresolved_psg9_incidents_val", "N/A")
        df_severe_incidents = filtered[filtered['Impact Level'].isin(['3', '4', '5'])].copy()
        total_severe_psg9_incidents = df_severe_incidents[df_severe_incidents['‡∏£‡∏´‡∏±‡∏™'].isin(psg9_r_codes_for_counting)].shape[0] if psg9_r_codes_for_counting else 0

        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("PSG9", f"{total_psg9_incidents_for_metric1:,}")
            with st.expander(f"‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ({total_psg9_incidents_for_metric1})"):
                psg9_df = filtered[filtered['‡∏£‡∏´‡∏±‡∏™'].isin(psg9_r_codes_for_counting)]
                cols_to_show_expander = [col for col in display_cols_common if col in psg9_df.columns]
                if not psg9_df.empty: st.dataframe(psg9_df[cols_to_show_expander], use_container_width=True, hide_index=True, column_config=date_format_config)
                else: st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ PSG9")
        with col2:
            st.metric("Sentinel", f"{total_sentinel_incidents_for_metric1:,}")
            with st.expander(f"‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ({total_sentinel_incidents_for_metric1})"):
                if 'Sentinel code for check' in filtered.columns and not filtered['Sentinel code for check'].empty:
                    sentinel_df = filtered[filtered['Sentinel code for check'].isin(sentinel_composite_keys)]
                    if not sentinel_df.empty:
                        cols_to_show_expander = [col for col in display_cols_common if col in sentinel_df.columns]
                        st.dataframe(sentinel_df[cols_to_show_expander], use_container_width=True, hide_index=True, column_config=date_format_config)
                    else:
                        st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ Sentinel")
                else:
                    st.info("‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Sentinel ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ")
        with col3:

            st.metric("E-I & 3-5 [all]", f"{total_severe_incidents:,}")
            with st.expander(f"‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ({total_severe_incidents})"):
                cols_to_show_expander = [col for col in display_cols_common if col in df_severe_incidents.columns]
                if not df_severe_incidents.empty: st.dataframe(df_severe_incidents[cols_to_show_expander], use_container_width=True, hide_index=True, column_config=date_format_config)
                else: st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á")
        col4, col5, col6 = st.columns(3)
        with col4:
            st.metric("E-I & 3-5 [PSG9]", f"{total_severe_psg9_incidents:,}")
            with st.expander(f"‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ({total_severe_psg9_incidents})"):
                severe_psg9_df = df_severe_incidents[df_severe_incidents['‡∏£‡∏´‡∏±‡∏™'].isin(psg9_r_codes_for_counting)]
                cols_to_show_expander = [col for col in display_cols_common if col in severe_psg9_df.columns]
                if not severe_psg9_df.empty: st.dataframe(severe_psg9_df[cols_to_show_expander], use_container_width=True, hide_index=True, column_config=date_format_config)
                else: st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ PSG9 ‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á")
        with col5:
            val_unresolved_all = f"{total_severe_unresolved_incidents_val:,}" if isinstance(total_severe_unresolved_incidents_val, int) else "N/A"
            st.metric(f"E-I & 3-5 [all] ‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç", val_unresolved_all)
            if isinstance(total_severe_unresolved_incidents_val, int) and total_severe_unresolved_incidents_val > 0:
                with st.expander(f"‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ({total_severe_unresolved_incidents_val})"):
                    unresolved_df_all = filtered[filtered['Impact Level'].isin(['3', '4', '5']) & filtered['Resulting Actions'].astype(str).isin(['None', '', 'nan'])]
                    cols_to_show_expander = [col for col in display_cols_common if col in unresolved_df_all.columns]
                    st.dataframe(unresolved_df_all[cols_to_show_expander], use_container_width=True, hide_index=True, column_config=date_format_config)
        with col6:
            val_unresolved_psg9 = f"{total_severe_unresolved_psg9_incidents_val:,}" if isinstance(total_severe_unresolved_psg9_incidents_val, int) else "N/A"
            st.metric(f"E-I & 3-5 [PSG9] ‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç", val_unresolved_psg9)
            if isinstance(total_severe_unresolved_psg9_incidents_val, int) and total_severe_unresolved_psg9_incidents_val > 0:
                with st.expander(f"‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ({total_severe_unresolved_psg9_incidents_val})"):
                    unresolved_df_all = filtered[filtered['Impact Level'].isin(['3', '4', '5']) & filtered['Resulting Actions'].astype(str).isin(['None', '', 'nan'])]
                    unresolved_df_psg9 = unresolved_df_all[unresolved_df_all['‡∏£‡∏´‡∏±‡∏™'].isin(psg9_r_codes_for_counting)]
                    cols_to_show_expander = [col for col in display_cols_common if col in unresolved_df_psg9.columns]
                    st.dataframe(unresolved_df_psg9[cols_to_show_expander], use_container_width=True, hide_index=True, column_config=date_format_config)

        st.markdown("---")
        monthly_counts = filtered.copy(); monthly_counts['‡πÄ‡∏î‡∏∑‡∏≠‡∏ô-‡∏õ‡∏µ'] = monthly_counts['Occurrence Date'].dt.strftime('%Y-%m')
        incident_trend = monthly_counts.groupby('‡πÄ‡∏î‡∏∑‡∏≠‡∏ô-‡∏õ‡∏µ').size().reset_index(name='‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå').sort_values(by='‡πÄ‡∏î‡∏∑‡∏≠‡∏ô-‡∏õ‡∏µ')
        if not incident_trend.empty:
            fig_trend = px.line(incident_trend, x='‡πÄ‡∏î‡∏∑‡∏≠‡∏ô-‡∏õ‡∏µ', y='‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå', title='‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå (‡∏Å‡∏£‡∏≠‡∏á‡πÅ‡∏•‡πâ‡∏ß) ‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô', markers=True, labels={'‡πÄ‡∏î‡∏∑‡∏≠‡∏ô-‡∏õ‡∏µ': '‡πÄ‡∏î‡∏∑‡∏≠‡∏ô', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå': '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á'}, line_shape='spline')
            fig_trend.update_traces(line=dict(width=3)); st.plotly_chart(fig_trend, use_container_width=True)
        else:
            st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô")

        st.markdown("---")
        total_incidents_filt = metrics_data_filt.get('total_processed_incidents', 0)
        resolved_incidents_filt = filtered[~filtered['Resulting Actions'].astype(str).isin(['None', '', 'nan'])].shape[0] if 'Resulting Actions' in filtered else 0
        status_data = pd.DataFrame({'‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞': ['‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå (‡∏Å‡∏£‡∏≠‡∏á‡πÅ‡∏•‡πâ‡∏ß)', '‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß'],'‡∏à‡∏≥‡∏ô‡∏ß‡∏ô': [total_incidents_filt, resolved_incidents_filt]})
        if total_incidents_filt > 0:
            fig_status = px.bar(status_data, x='‡∏à‡∏≥‡∏ô‡∏ß‡∏ô', y='‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞', orientation='h', title='‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß (‡∏Å‡∏£‡∏≠‡∏á‡πÅ‡∏•‡πâ‡∏ß)', text='‡∏à‡∏≥‡∏ô‡∏ß‡∏ô', color='‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞',
                                color_discrete_map={'‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå (‡∏Å‡∏£‡∏≠‡∏á‡πÅ‡∏•‡πâ‡∏ß)': '#1f77b4', '‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß': '#2ca02c'}, labels={'‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞': '', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô': '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô'})
            fig_status.update_layout(yaxis={'categoryorder': 'total ascending'}, showlegend=False); st.plotly_chart(fig_status, use_container_width=True)
        else:
            st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç")

elif selected_page == "Incidents Analysis":
    if filtered.empty: st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á")
    else: render_incidents_analysis(filtered)

elif selected_page == "Risk Matrix (Interactive)":
    if filtered.empty: st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á")
    else: render_risk_matrix_interactive(filtered, key_prefix="main_rmx")

elif selected_page == "Risk level":
    if filtered.empty: st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á")
    else: render_risk_level_summary(filtered)

elif selected_page == "Risk Register Assistant":
    st.markdown("<h4 style='color: #001f3f;'>Risk Register Assistant</h4>", unsafe_allow_html=True)
    st.info("‡∏õ‡πâ‡∏≠‡∏ô '‡∏£‡∏´‡∏±‡∏™' ‡∏´‡∏£‡∏∑‡∏≠ '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å")
    query = st.text_input("‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏´‡∏±‡∏™ ‡∏´‡∏£‡∏∑‡∏≠ ‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤:", key="risk_register_query")
    if st.button("‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤", type="primary", use_container_width=True):
        if not query.strip(): st.warning("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏õ‡πâ‡∏≠‡∏ô‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤")
        elif filtered.empty: st.warning("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ (‡∏ï‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô)")
        else:
            with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤..."):
                result = get_risk_register_consultation(query=query, df=filtered, risk_mitigation_df=df_mitigation)
                st.markdown("---")
                if "error" in result:
                    st.error(result["error"])
                else:
                    st.subheader("Result Review")
                    st.markdown(f"**{result.get('incident_code','N/A')} - {result.get('incident_name','N/A')}**")
                    c1, c2, c3 = st.columns(3)
                    c1.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á", f"{result.get('total_occurrences', 0)} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á")
                    c2.metric("Impact Level ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î", result.get('max_impact_level', 'N/A'))
                    c3.metric("Frequency Level", result.get('frequency_level', 'N/A'))

                    st.markdown("---")
                    st.markdown(f"##### Review Result: ‡∏û‡∏ö {result.get('total_occurrences', 0)} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á:")
                    incident_details_df = result.get('incident_df', pd.DataFrame())
                    if not incident_details_df.empty:
                        incident_details_df = incident_details_df.sort_values(by='Occurrence Date', ascending=False)
                        for _, row in incident_details_df.iterrows():
                            event_date = row['Occurrence Date'].strftime('%d %b %Y, %H:%M') if pd.notna(row['Occurrence Date']) else 'N/A'
                            impact = row.get('Impact', 'N/A'); impact_level = row.get('Impact Level', 'N/A')
                            details = row.get('‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î_Anonymized', '‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î')
                            st.markdown(f"""<div style="border-left: 4px solid #eee; padding-left: 15px; margin-bottom: 15px;">
                            <b>{event_date}</b> ‚Ä¢ {impact} (‡∏£‡∏∞‡∏î‡∏±‡∏ö {impact_level})<br><em>{details}</em>
                            </div>""", unsafe_allow_html=True)
                    else:
                        st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå")

                    st.markdown("---")
                    st.markdown("**Risk Transfer & Prevention:**")
                    st.info(result.get('existing_prevention', 'N/A'))
                    st.markdown("**Risk Monitor:**")
                    st.info(result.get('existing_monitor', 'N/A'))

elif selected_page == "Heatmap ‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô":
    st.markdown("<h4 style='color: #001f3f;'>Heatmap: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô</h4>", unsafe_allow_html=True)
    if filtered.empty:
        st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á")
    else:
        st.info("üí° Heatmap ‡∏ô‡∏µ‡πâ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Top N ‡∏£‡∏´‡∏±‡∏™")
        heatmap_req_cols = ['‡∏£‡∏´‡∏±‡∏™', '‡πÄ‡∏î‡∏∑‡∏≠‡∏ô', '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á', 'Incident']
        if not all(col in filtered.columns for col in heatmap_req_cols):
            st.warning("‡∏Ç‡∏≤‡∏î‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Heatmap")
        else:
            df_heat = filtered.copy();
            df_heat['incident_label'] = df_heat['‡∏£‡∏´‡∏±‡∏™'] + " | " + df_heat['‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á'].fillna('')
            total_counts = df_heat['incident_label'].value_counts().reset_index();
            total_counts.columns = ['incident_label', 'total_count']

            # --- START: ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç Slider ---
            total_incident_types = len(total_counts)
            SLIDER_MIN = 5  # ‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà Slider ‡∏à‡∏∞‡πÄ‡∏£‡∏¥‡πà‡∏°

            if total_incident_types <= SLIDER_MIN:
                # ‡∏ñ‡πâ‡∏≤‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö 5 (‡πÄ‡∏ä‡πà‡∏ô 2) ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏™‡∏î‡∏á slider
                top_n = total_incident_types
                if total_incident_types > 0:
                    st.caption(f"‡πÅ‡∏™‡∏î‡∏á‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {top_n} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ (‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏°‡∏µ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤ {SLIDER_MIN})")
            else:
                # ‡∏ñ‡πâ‡∏≤‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 5 (‡πÄ‡∏ä‡πà‡∏ô 6) ‡∏ñ‡∏∂‡∏á‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á slider
                slider_max = min(50, total_incident_types)
                slider_default = min(20, total_incident_types)
                top_n = st.slider("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Top N:", SLIDER_MIN, slider_max, slider_default, 5, key="top_n_slider")
            # --- END: ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç Slider ---

            if top_n == 0:
                st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÉ‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ô‡∏µ‡πâ")
                df_heat_filtered_view = pd.DataFrame(columns=df_heat.columns)  # ‡∏™‡∏£‡πâ‡∏≤‡∏á df ‡∏ß‡πà‡∏≤‡∏á
            else:
                top_incident_labels = total_counts.nlargest(top_n, 'total_count')['incident_label']
                df_heat_filtered_view = df_heat[df_heat['incident_label'].isin(top_incident_labels)]

            try:
                heatmap_pivot = pd.pivot_table(df_heat_filtered_view, values='Incident', index='incident_label',
                                               columns='‡πÄ‡∏î‡∏∑‡∏≠‡∏ô', aggfunc='count', fill_value=0)
                sorted_month_names = [v for k, v in sorted(month_label.items())]
                available_months = [m for m in sorted_month_names if m in heatmap_pivot.columns]
                if available_months:
                    heatmap_pivot = heatmap_pivot[available_months].reindex(top_incident_labels).dropna(
                        how='all').fillna(0)
                    if not heatmap_pivot.empty:
                        fig_heatmap = px.imshow(heatmap_pivot, labels=dict(x="‡πÄ‡∏î‡∏∑‡∏≠‡∏ô", y="‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå", color="‡∏à‡∏≥‡∏ô‡∏ß‡∏ô"),
                                                text_auto=True, aspect="auto", color_continuous_scale='Reds')
                        fig_heatmap.update_layout(title_text=f"Top {top_n}",
                                                  height=max(600, len(heatmap_pivot.index) * 25));
                        fig_heatmap.update_xaxes(side="top")
                        st.plotly_chart(fig_heatmap, use_container_width=True)
                    else:
                        st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Heatmap")
                else:
                    st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô")

            except Exception as e:
                    st.error(f"‡∏™‡∏£‡πâ‡∏≤‡∏á Heatmap ‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
            st.markdown("---")
            st.markdown("<h5 style='color: #003366;'>Heatmap ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏° Safety Goal</h5>", unsafe_allow_html=True)
            goal_search_terms = {"Patient Safety/...": "Patient Safety", "Specific Clinical": "Specific Clinical", "Personnel Safety": "Personnel Safety", "Organization Safety": "Organization Safety"}
            for display_name, search_term in goal_search_terms.items():
                df_goal_filtered = df_heat[df_heat['‡∏´‡∏°‡∏ß‡∏î'].astype(str).str.contains(search_term, na=False, case=False)].copy()
                if df_goal_filtered.empty:
                    st.markdown(f"**{display_name}**: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"); st.markdown("---"); continue
                try:
                    goal_pivot = pd.pivot_table(df_goal_filtered, values='Incident', index='incident_label', columns='‡πÄ‡∏î‡∏∑‡∏≠‡∏ô', aggfunc='count', fill_value=0)
                    if not goal_pivot.empty:
                        sorted_month_names = [v for k, v in sorted(month_label.items())]
                        available_months_goal = [m for m in sorted_month_names if m in goal_pivot.columns]
                        if available_months_goal:
                            goal_pivot = goal_pivot[available_months_goal]
                            incident_counts_in_goal = df_goal_filtered['incident_label'].value_counts()
                            goal_pivot = goal_pivot.reindex(incident_counts_in_goal.index).dropna(how='all').fillna(0)
                            if not goal_pivot.empty:
                                fig_goal = px.imshow(goal_pivot, labels=dict(x="‡πÄ‡∏î‡∏∑‡∏≠‡∏ô", y="‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå", color="‡∏à‡∏≥‡∏ô‡∏ß‡∏ô"), text_auto=True, aspect="auto", color_continuous_scale='Oranges')
                                fig_goal.update_layout(title_text=f"<b>{display_name}</b>", height=max(500, len(goal_pivot.index)*28)); fig_goal.update_xaxes(side="top")
                                st.plotly_chart(fig_goal, use_container_width=True)
                            else:
                                st.info(f"‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Pivot '{display_name}'")
                        else:
                            st.info(f"‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô '{display_name}'")
                    else:
                        st.info(f"‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Pivot '{display_name}'")
                    st.markdown("---")
                except Exception as e:
                    st.error(f"‡∏™‡∏£‡πâ‡∏≤‡∏á Heatmap '{display_name}' ‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")

elif selected_page == "Sentinel Events & Top 10":
    st.markdown("<h4 style='color: #001f3f;'>‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ Sentinel Events</h4>", unsafe_allow_html=True)
    if filtered.empty:
        st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á")
    elif 'Sentinel code for check' in filtered.columns:
        sentinel_events = filtered[filtered['Sentinel code for check'].isin(sentinel_composite_keys)].copy()
        if not sentinel_events.empty:
            if 'Sentinel2024_df' in globals() and not Sentinel2024_df.empty and '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á' in Sentinel2024_df.columns:
                try:
                    sentinel_events = pd.merge(sentinel_events, Sentinel2024_df[['‡∏£‡∏´‡∏±‡∏™', 'Impact', '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á']].rename(columns={'‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á': 'Sentinel Event Name'}), on=['‡∏£‡∏´‡∏±‡∏™', 'Impact'], how='left')
                    if 'Sentinel Event Name' not in display_cols_common: display_cols_common.insert(2, 'Sentinel Event Name')
                except Exception as e:
                    st.warning(f"Merge Sentinel name failed: {e}")
            cols_to_show_sentinel = [col for col in display_cols_common if col in sentinel_events.columns]
            date_format_config = {"Occurrence Date": st.column_config.DatetimeColumn("‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î", format="DD/MM/YYYY HH:mm")}
            st.dataframe(sentinel_events[cols_to_show_sentinel], use_container_width=True, hide_index=True, column_config=date_format_config)
        else:
            st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö Sentinel Events")
    else:
        st.warning("‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Sentinel ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ")

    st.markdown("---")
    st.subheader("Top 10 ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå (‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà)")
    if filtered.empty:
        st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á")
    else:
        df_freq_filt = filtered['Incident'].value_counts().reset_index(); df_freq_filt.columns = ['Incident', 'count']
        if not df_freq_filt.empty:
            top10_df = df_freq_filt.nlargest(10, 'count')
            incident_names_filt = filtered[['Incident', '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á']].drop_duplicates()
            top10_df = pd.merge(top10_df, incident_names_filt, on='Incident', how='left')
            st.dataframe(top10_df[['Incident', '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á', 'count']], hide_index=True, use_container_width=True, column_config={"Incident": "‡∏£‡∏´‡∏±‡∏™", "count":"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô"})
        else:
            st.warning("‡πÅ‡∏™‡∏î‡∏á Top 10 ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ")

elif selected_page == "‡∏Å‡∏£‡∏≤‡∏ü‡∏™‡∏£‡∏∏‡∏õ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå (‡∏£‡∏≤‡∏¢‡∏°‡∏¥‡∏ï‡∏¥)":
    st.markdown("<h4 style='color: #001f3f;'>‡∏Å‡∏£‡∏≤‡∏ü‡∏™‡∏£‡∏∏‡∏õ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå (‡∏£‡∏≤‡∏¢‡∏°‡∏¥‡∏ï‡∏¥)</h4>", unsafe_allow_html=True)
    if filtered.empty:
        st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á")
    else:
        pastel_color_discrete_map_dimensions = {'Extreme':'#d9534f', 'High': '#FFCC99', 'Medium': '#FFFF99', 'Low': '#99FF99', 'Undefined': '#D3D3D3', 'Critical': '#FF9999'}
        tab1_v, tab2_v, tab3_v, tab4_v = st.tabs(["üëÅÔ∏èBy Goals", "üëÅÔ∏èBy Group", "üëÅÔ∏èBy Shift", "üëÅÔ∏èBy Place"])
        df_charts = filtered.copy(); df_charts['Count'] = 1
        with tab1_v:
            st.markdown("‡∏ï‡∏≤‡∏°‡∏´‡∏°‡∏ß‡∏î")
            if '‡∏´‡∏°‡∏ß‡∏î' in df_charts.columns:
                df_c1 = df_charts[~df_charts['‡∏´‡∏°‡∏ß‡∏î'].astype(str).isin(['N/A', 'None'])]
                if not df_c1.empty:
                    fig_c1 = px.bar(df_c1.groupby(['‡∏´‡∏°‡∏ß‡∏î', 'Category Color'], observed=True).size().reset_index(name='Count'), x='‡∏´‡∏°‡∏ß‡∏î', y='Count', color='Category Color', color_discrete_map=pastel_color_discrete_map_dimensions, title="‡∏ï‡∏≤‡∏°‡∏´‡∏°‡∏ß‡∏î")
                    fig_c1.update_layout(xaxis={'categoryorder':'total descending'}); st.plotly_chart(fig_c1, use_container_width=True)
                else: st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏°‡∏ß‡∏î")
            else: st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö '‡∏´‡∏°‡∏ß‡∏î'")
        with tab2_v:
            st.markdown("‡∏ï‡∏≤‡∏°‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô")
            if '‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô' in df_charts.columns:
                df_c2 = df_charts[~df_charts['‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô'].astype(str).isin(['N/A', 'None'])]
                if not df_c2.empty:
                    fig_c2 = px.bar(df_c2.groupby(['‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô', 'Category Color'], observed=True).size().reset_index(name='Count'), x='‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô', y='Count', color='Category Color', color_discrete_map=pastel_color_discrete_map_dimensions, title="‡∏ï‡∏≤‡∏°‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô")
                    fig_c2.update_layout(xaxis={'categoryorder':'total descending'}); st.plotly_chart(fig_c2, use_container_width=True)
                else: st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô")
            else: st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö '‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô'")
        with tab3_v:
            st.markdown("‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏£")
            if '‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤/‡πÄ‡∏ß‡∏£' in df_charts.columns:
                df_c3 = df_charts[df_charts['‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤/‡πÄ‡∏ß‡∏£'].notna() & ~df_charts['‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤/‡πÄ‡∏ß‡∏£'].astype(str).isin(['None', 'N/A'])]
                if not df_c3.empty:
                    fig_c3 = px.bar(df_c3.groupby(['‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤/‡πÄ‡∏ß‡∏£', 'Category Color'], observed=True).size().reset_index(name='Count'), x='‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤/‡πÄ‡∏ß‡∏£', y='Count', color='Category Color', color_discrete_map=pastel_color_discrete_map_dimensions, title="‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏£")
                    fig_c3.update_layout(xaxis={'categoryorder':'array', 'categoryarray':['‡πÄ‡∏ä‡πâ‡∏≤','‡∏ö‡πà‡∏≤‡∏¢','‡∏î‡∏∂‡∏Å']})
                    st.plotly_chart(fig_c3, use_container_width=True)
                else: st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ß‡∏£")
            else: st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö '‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤/‡πÄ‡∏ß‡∏£'")
        with tab4_v:
            st.markdown("‡∏ï‡∏≤‡∏°‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà")
            if '‡∏ä‡∏ô‡∏¥‡∏î‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà' in df_charts.columns:
                df_c4 = df_charts[df_charts['‡∏ä‡∏ô‡∏¥‡∏î‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà'].notna() & ~df_charts['‡∏ä‡∏ô‡∏¥‡∏î‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà'].astype(str).isin(['None', 'N/A'])]
                if not df_c4.empty:
                    place_counts = df_c4['‡∏ä‡∏ô‡∏¥‡∏î‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà'].value_counts()
                    threshold = max(5, int(len(place_counts) * 0.05))
                    other_places = place_counts[place_counts < threshold].index
                    df_c4['‡∏ä‡∏ô‡∏¥‡∏î‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà_Agg'] = df_c4['‡∏ä‡∏ô‡∏¥‡∏î‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà'].apply(lambda x: '‡∏≠‡∏∑‡πà‡∏ô‡πÜ' if x in other_places else x)
                    fig_c4 = px.bar(df_c4.groupby(['‡∏ä‡∏ô‡∏¥‡∏î‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà_Agg', 'Category Color'], observed=True).size().reset_index(name='Count'), x='‡∏ä‡∏ô‡∏¥‡∏î‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà_Agg', y='Count', color='Category Color', color_discrete_map=pastel_color_discrete_map_dimensions, title="‡∏ï‡∏≤‡∏°‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà")
                    fig_c4.update_layout(xaxis_title="‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà", xaxis={'categoryorder':'total descending'})
                    st.plotly_chart(fig_c4, use_container_width=True)
                else: st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà")
            else: st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö '‡∏ä‡∏ô‡∏¥‡∏î‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà'")

elif selected_page == "‡∏™‡∏£‡∏∏‡∏õ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ï‡∏≤‡∏° Safety Goals":
    st.markdown("<h4 style='color: #001f3f;'>‡∏™‡∏£‡∏∏‡∏õ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ï‡∏≤‡∏° Safety Goals</h4>", unsafe_allow_html=True)
    if filtered.empty:
        st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á")
    else:
        # --- Part 1: Summary Tables ---
        for display_name, cat_name in goal_definitions.items():
            st.subheader(display_name)
            try:
                summary_table = create_goal_summary_table(
                    data_df_goal=filtered,
                    goal_category_name_param=cat_name
                )
                if summary_table is not None and not summary_table.empty:
                    st.dataframe(summary_table, use_container_width=True, hide_index=True)
                else:
                    st.info(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {display_name}")
            except Exception as e:
                st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á {display_name}: {e}")

        # ‡∏à‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏£‡∏≤‡∏ü/ sunburst ‡∏†‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏á (‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏ï‡∏±‡∏î‡∏≠‡∏≠‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£)

elif selected_page == "Persistence Risk Index":
    st.markdown("<h4 style='color: #001f3f;'>‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏£‡∏∑‡πâ‡∏≠‡∏£‡∏±‡∏á</h4>", unsafe_allow_html=True)
    if filtered.empty:
        st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á")
    else:
        st.info("‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏ã‡πâ‡∏≥ ‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢")
        min_date_filt = filtered['Occurrence Date'].min(); max_date_filt = filtered['Occurrence Date'].max()
        total_month_filt = 0
        if pd.notna(min_date_filt) and pd.notna(max_date_filt):
            max_p_filt = max_date_filt.to_period('M'); min_p_filt = min_date_filt.to_period('M')
            total_month_filt = max(1, (max_p_filt.year - min_p_filt.year) * 12 + (max_p_filt.month - min_p_filt.month) + 1)

        persistence_df = calculate_persistence_risk_score(filtered, total_month_filt)
        if not persistence_df.empty:
            display_df_persistence = persistence_df.rename(columns={
                '‡∏£‡∏´‡∏±‡∏™': 'Incident Code',
                '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á': 'Incident Name',
                'Average_Ordinal_Risk_Score': 'Avg Ordinal Risk',
                'Total_Occurrences': 'Total',
                'Incident_Rate_Per_Month': 'Rate/Month',
                'Persistence_Risk_Score': 'Persistence Score'
            })
            st.dataframe(display_df_persistence[['Incident Code','Incident Name','Total','Avg Ordinal Risk','Rate/Month','Persistence Score']],
                         use_container_width=True, hide_index=True)
            st.markdown("---"); st.markdown("##### ‡∏Å‡∏£‡∏≤‡∏ü‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")
            fig = px.scatter(persistence_df,
                             x='Incident_Rate_Per_Month', y='Average_Ordinal_Risk_Score',
                             size='Total_Occurrences', hover_name='‡∏£‡∏´‡∏±‡∏™',
                             color='Persistence_Risk_Score',
                             labels={'Incident_Rate_Per_Month':'‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô', 'Average_Ordinal_Risk_Score':'‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ (ordinal)'})
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Persistence Risk")

elif selected_page == "Early Warning: ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏™‡∏π‡∏á‡∏Ç‡∏∂‡πâ‡∏ô":
    st.markdown("<h4 style='color:#001f3f;'>Early Warning</h4>", unsafe_allow_html=True)
    if filtered.empty:
        st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á")
    else:
        c1, c2, c3 = st.columns(3)
        with c1: horizon = st.slider("‡∏ä‡πà‡∏ß‡∏á‡∏Ñ‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ì‡πå (‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)", 1, 12, 3)
        with c2: w1 = st.slider("‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà", 0.0, 1.0, 0.34)
        with c3: w2 = st.slider("‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á", 0.0, 1.0, 0.33)
        w3 = max(0.0, 1.0 - (w1 + w2))
        st.caption(f"‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏° = {w3:.2f}")
        try:
            res = prioritize_incidents_nb_logit_v2(_df=filtered, horizon=horizon, w_freq=w1, w_sev=w2, w_trend=w3)
        except Exception as e:
            st.error(f"‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
            res = pd.DataFrame()
        if res.empty:
            st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Early Warning")
        else:
            st.dataframe(res.rename(columns={'‡∏£‡∏´‡∏±‡∏™':'Incident Code','‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á':'Incident Name','total':'Total','avg_risk':'Avg Risk','score':'Priority Score'}),
                         use_container_width=True, hide_index=True)

elif selected_page == "‡∏ö‡∏ó‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£":
    st.markdown("<h4 style='color: #001f3f;'>‡∏ö‡∏ó‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£</h4>", unsafe_allow_html=True)
    if filtered.empty:
        st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á")
    else:
        # --- START: Dependency Injection (‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡πà‡∏≠‡∏ô) ---
        # 1. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤
        min_date_filt = filtered['Occurrence Date'].min();
        max_date_filt = filtered['Occurrence Date'].max()
        min_date_str = min_date_filt.strftime('%d/%m/%Y') if pd.notna(min_date_filt) else "N/A"
        max_date_str = max_date_filt.strftime('%d/%m/%Y') if pd.notna(max_date_filt) else "N/A"
        total_month = 0
        if pd.notna(min_date_filt) and pd.notna(max_date_filt):
            max_p_filt = max_date_filt.to_period('M');
            min_p_filt = min_date_filt.to_period('M')
            total_month = max(1, (max_p_filt.year - min_p_filt.year) * 12 + (max_p_filt.month - min_p_filt.month) + 1)

        # 2. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Metrics (‡∏î‡∏∂‡∏á‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡πâ‡∏≤ Dashboard)
        metrics_data = {}
        metrics_data['total_processed_incidents'] = filtered.shape[0]
        metrics_data['total_psg9_incidents_for_metric1'] = \
        filtered[filtered['‡∏£‡∏´‡∏±‡∏™'].isin(psg9_r_codes_for_counting)].shape[0] if psg9_r_codes_for_counting else 0
        metrics_data['total_sentinel_incidents_for_metric1'] = \
        filtered[filtered['Sentinel code for check'].isin(sentinel_composite_keys)].shape[
            0] if 'Sentinel code for check' in filtered.columns and sentinel_composite_keys else 0

        severe_impact_levels_list = ['3', '4', '5']
        df_severe_filt = filtered[filtered['Impact Level'].isin(severe_impact_levels_list)].copy()
        metrics_data['total_severe_incidents'] = df_severe_filt.shape[0]

        if 'Resulting Actions' in filtered.columns:
            unresolved_filt = df_severe_filt[df_severe_filt['Resulting Actions'].astype(str).isin(['None', '', 'nan'])]
            metrics_data['total_severe_unresolved_incidents_val'] = unresolved_filt.shape[0]
        else:
            metrics_data['total_severe_unresolved_incidents_val'] = "N/A"

        # 3. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Top 10 (‡∏î‡∏∂‡∏á‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡πâ‡∏≤ Sentinel)
        df_freq = filtered['Incident'].value_counts().reset_index()
        df_freq.columns = ['Incident', 'count']
        # --- END: Dependency Injection ---

        st.markdown(f"**‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á:** ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏™‡∏£‡∏∏‡∏õ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•")
        st.markdown(f"**‡∏ä‡πà‡∏ß‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå:** {min_date_str} ‡∏ñ‡∏∂‡∏á {max_date_str} (‡∏£‡∏ß‡∏° {total_month} ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)")
        st.markdown(f"**‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î:** {metrics_data.get('total_processed_incidents', 0):,} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        st.markdown("---")

        # --- 1. ‡πÅ‡∏î‡∏ä‡∏ö‡∏≠‡∏£‡πå‡∏î‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏° ---
        st.subheader("1. ‡πÅ‡∏î‡∏ä‡∏ö‡∏≠‡∏£‡πå‡∏î‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°")
        col1_m, col2_m, col3_m, col4_m, col5_m = st.columns(5)
        with col1_m:
            st.metric("‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", f"{metrics_data.get('total_processed_incidents', 0):,}")
        with col2_m:
            st.metric("Sentinel Events", f"{metrics_data.get('total_sentinel_incidents_for_metric1', 0):,}")
        with col3_m:
            st.metric("‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ø 9 ‡∏Ç‡πâ‡∏≠", f"{metrics_data.get('total_psg9_incidents_for_metric1', 0):,}")
        with col4_m:
            st.metric("‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏™‡∏π‡∏á (E-I & 3-5)", f"{metrics_data.get('total_severe_incidents', 0):,}")
        with col5_m:
            val_unresolved = metrics_data.get('total_severe_unresolved_incidents_val', 'N/A')
            st.metric("‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏™‡∏π‡∏á & ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç",
                      f"{val_unresolved:,}" if isinstance(val_unresolved, int) else val_unresolved)
        st.markdown("---")

        # --- 2. Risk Matrix ‡πÅ‡∏•‡∏∞ Top 10 ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå ---
        st.subheader("2. Risk Matrix ‡πÅ‡∏•‡∏∞ Top 10 ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå")
        col_matrix, col_top10 = st.columns(2)
        with col_matrix:
            st.markdown("##### Risk Matrix")
            impact_level_keys = ['5', '4', '3', '2', '1']
            freq_level_keys = ['1', '2', '3', '4', '5']
            matrix_df = filtered[
                filtered['Impact Level'].isin(impact_level_keys) & filtered['Frequency Level'].isin(
                    freq_level_keys)]
            if not matrix_df.empty:
                matrix_data = pd.crosstab(matrix_df['Impact Level'], matrix_df['Frequency Level'])
                matrix_data = matrix_data.reindex(index=impact_level_keys, columns=freq_level_keys, fill_value=0)
                impact_labels = {'5': "5 (Extreme)", '4': "4 (Major)", '3': "3 (Moderate)", '2': "2 (Minor)",
                                 '1': "1 (Insignificant)"}
                freq_labels = {'1': "F1", '2': "F2", '3': "F3", '4': "F4", '5': "F5"}
                st.table(matrix_data.rename(index=impact_labels, columns=freq_labels))
            else:
                st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Risk Matrix")
        with col_top10:
            st.markdown("##### Top 10 ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå (‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà)")
            if not df_freq.empty:
                df_freq_top10 = df_freq.nlargest(10, 'count').copy()
                display_top10 = pd.merge(df_freq_top10,
                                         filtered[['Incident', '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á']].drop_duplicates(),
                                         on='Incident', how='left')
                # ‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏Ñ‡πà ‡∏£‡∏´‡∏±‡∏™ ‡πÅ‡∏•‡∏∞ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô (‡∏ï‡∏≤‡∏°‡πÇ‡∏Ñ‡πâ‡∏î‡πÄ‡∏î‡∏¥‡∏°)
                st.dataframe(display_top10[['Incident', 'count']], hide_index=True,
                             use_container_width=True,
                             column_config={"Incident": "‡∏£‡∏´‡∏±‡∏™",
                                            "count": "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô"})
            else:
                st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Top 10")
        st.markdown("---")

        # --- 3. ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ Sentinel Events ---
        st.subheader("3. ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ Sentinel Events")
        if 'Sentinel code for check' in filtered.columns:
            sentinel_events_df = filtered[filtered['Sentinel code for check'].isin(sentinel_composite_keys)]
            if not sentinel_events_df.empty:
                st.dataframe(
                    sentinel_events_df[['Occurrence Date', 'Incident', 'Impact', '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î_Anonymized']],
                    hide_index=True, use_container_width=True,
                    column_config={"Occurrence Date": "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î", "Incident": "‡∏£‡∏´‡∏±‡∏™", "Impact": "‡∏£‡∏∞‡∏î‡∏±‡∏ö",
                                   "‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î_Anonymized": "‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î"})
            else:
                st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö Sentinel Events ‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å")
        else:
            st.warning("‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Sentinel ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ")
        st.markdown("---")

        # --- 4. PSG9 Summary ---
        st.subheader("4. ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ï‡∏≤‡∏°‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢ 9 ‡∏Ç‡πâ‡∏≠")
        # (‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô Helper ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏ã‡πà‡∏≠‡∏°‡πÑ‡∏õ‡πÅ‡∏•‡πâ‡∏ß)
        psg9_summary_table = create_psg9_summary_table(filtered)
        if psg9_summary_table is not None and not psg9_summary_table.empty:
            st.table(psg9_summary_table)
        else:
            st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö PSG9 ‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏µ‡πâ")
        st.markdown("---")

        # --- 5. ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç ---
        st.subheader("5. ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á (E-I & 3-5) ‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç")
        if 'Resulting Actions' in filtered.columns:
            unresolved_severe_df = filtered[
                filtered['Impact Level'].isin(['3', '4', '5']) &
                filtered['Resulting Actions'].astype(str).isin(['None', '', 'nan'])
                ]
            if not unresolved_severe_df.empty:
                display_cols_unresolved = ['Occurrence Date', 'Incident', 'Impact', '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î_Anonymized']
                st.dataframe(
                    unresolved_severe_df[display_cols_unresolved],
                    hide_index=True,
                    use_container_width=True,
                    column_config={
                        "Occurrence Date": st.column_config.DatetimeColumn(
                            "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î",
                            format="DD/MM/YYYY",
                        ),
                        "Incident": "‡∏£‡∏´‡∏±‡∏™",
                        "Impact": "‡∏£‡∏∞‡∏î‡∏±‡∏ö",
                        "‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î_Anonymized": "‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î"
                    }
                )
            else:
                st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏µ‡πâ")
        st.markdown("---")

        # --- 6. ‡∏™‡∏£‡∏∏‡∏õ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ï‡∏≤‡∏°‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ Safety Goals ---
        st.subheader("6. ‡∏™‡∏£‡∏∏‡∏õ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ï‡∏≤‡∏°‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ Safety Goals")
        # (goal_definitions ‡∏ñ‡∏π‡∏Å‡∏ô‡∏¥‡∏¢‡∏≤‡∏°‡πÑ‡∏ß‡πâ‡πÉ‡∏ô Section 5)
        for display_name, cat_name in goal_definitions.items():
            st.markdown(f"##### {display_name}")

            # --- ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏Å‡πâ ---
            # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô "‡∏á‡πà‡∏≤‡∏¢" ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏°‡∏µ‡πÉ‡∏ô Section 7
            # ‡πÇ‡∏î‡∏¢‡∏ï‡∏±‡∏î‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô (e_up..., is_org_safety) ‡∏ó‡∏¥‡πâ‡∏á‡πÑ‡∏õ
            summary_table = create_goal_summary_table(filtered, cat_name)

            if summary_table is not None and not summary_table.empty:
                # ‡πÉ‡∏ä‡πâ st.dataframe ‡πÅ‡∏ó‡∏ô st.table ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏¢‡∏≤‡∏ß‡πÜ ‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤
                st.dataframe(summary_table, use_container_width=True, hide_index=True)
            else:
                st.info(f"‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö '{display_name}'")
        st.markdown("---")

        # --- 7. Early Warning (Top 5) ---
        st.subheader("7. Early Warning: ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏™‡∏π‡∏á‡∏Ç‡∏∂‡πâ‡∏ô (Top 5)")
        st.write(
            "‡πÅ‡∏™‡∏î‡∏á Top 5 ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏à‡∏±‡∏î‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î ‡πÇ‡∏î‡∏¢‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏à‡∏≤‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢")

        # --- ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏Å‡πâ ---
        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô "‡∏á‡πà‡∏≤‡∏¢" (stub) ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏°‡∏µ‡πÉ‡∏ô Section 7
        # ‡πÇ‡∏î‡∏¢‡∏ï‡∏±‡∏î‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ (min_months, min_total) ‡∏ó‡∏¥‡πâ‡∏á
        early_warning_df = prioritize_incidents_nb_logit_v2(filtered, horizon=3)

        if not early_warning_df.empty:
            top_ew_incidents = early_warning_df.head(5).copy()

            # ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏Å‡πâ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô "‡∏á‡πà‡∏≤‡∏¢"
            display_ew_df = top_ew_incidents.rename(
                columns={'‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á': '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå',
                         'score': '‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç'})

            # ‡∏ï‡∏±‡∏î‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '‡∏Ñ‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÄ‡∏´‡∏ï‡∏∏‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á (3 ‡∏î.)' ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏á‡πà‡∏≤‡∏¢‡∏ó‡∏¥‡πâ‡∏á‡πÑ‡∏õ
            st.dataframe(
                display_ew_df[['‡∏£‡∏´‡∏±‡∏™', '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå', '‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç']],
                column_config={
                    "‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç": st.column_config.ProgressColumn("‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç", format="%.3f", min_value=0,
                                                                      max_value=float(
                                                                          display_ew_df['‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç'].max())),
                },
                use_container_width=True, hide_index=True
            )
        else:
            st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå Early Warning")
        st.markdown("---")

        # --- 8. ‡∏™‡∏£‡∏∏‡∏õ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏£‡∏∑‡πâ‡∏≠‡∏£‡∏±‡∏á (Top 5) ---
        st.subheader("8. ‡∏™‡∏£‡∏∏‡∏õ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏£‡∏∑‡πâ‡∏≠‡∏£‡∏±‡∏á (Persistence Risk - Top 5)")
        st.write("‡πÅ‡∏™‡∏î‡∏á Top 5 ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏ö‡πà‡∏≠‡∏¢‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏™‡∏π‡∏á ‡∏ã‡∏∂‡πà‡∏á‡∏Ñ‡∏ß‡∏£‡∏ó‡∏ö‡∏ó‡∏ß‡∏ô‡πÄ‡∏ä‡∏¥‡∏á‡∏£‡∏∞‡∏ö‡∏ö")
        persistence_df_exec = calculate_persistence_risk_score(filtered, total_month)
        if not persistence_df_exec.empty:
            top_persistence_incidents = persistence_df_exec.head(5)
            display_df_persistence = top_persistence_incidents.rename(
                columns={'Persistence_Risk_Score': '‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡∏∑‡πâ‡∏≠‡∏£‡∏±‡∏á',
                         'Average_Ordinal_Risk_Score': '‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢'})
            st.dataframe(
                display_df_persistence[['‡∏£‡∏´‡∏±‡∏™', '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á', '‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢', '‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡∏∑‡πâ‡∏≠‡∏£‡∏±‡∏á']],
                column_config={
                    "‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢": st.column_config.NumberColumn(format="%.2f"),
                    "‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡∏∑‡πâ‡∏≠‡∏£‡∏±‡∏á": st.column_config.ProgressColumn("‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡∏∑‡πâ‡∏≠‡∏£‡∏±‡∏á", min_value=0, max_value=2,
                                                                         format="%.2f")
                },
                use_container_width=True,
                hide_index=True  # ‡πÄ‡∏û‡∏¥‡πà‡∏° hide_index
            )
        else:
            st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏£‡∏∑‡πâ‡∏≠‡∏£‡∏±‡∏á")

# =========================
# 9) Download ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (Main Area, uses 'filtered')
# =========================
@st.cache_data
def _to_csv_bytes(df: pd.DataFrame) -> bytes:
    cols_for_download = [
        '‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ö', '‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô', '‡∏ß‡∏±‡∏ô-‡πÄ‡∏ß‡∏•‡∏≤ ‡∏ó‡∏µ‡πà‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô', '‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏´‡∏ï‡∏∏',
        'Occurrence Date', 'Incident', '‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á', 'Impact', 'Impact Level',
        'Frequency Level', 'Risk Level', 'Category Color', '‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏á‡∏≤‡∏ô', '‡∏´‡∏°‡∏ß‡∏î',
        '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î', 'Resulting Actions', '‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô_norm',
        'FY_int', 'FQuarter', 'FY_Quarter',
        '‡∏£‡∏´‡∏±‡∏™',
    ]
    cols_present_for_download = [c for c in cols_for_download if c in df.columns]
    try:
        return df[cols_present_for_download].to_csv(index=False).encode("utf-8-sig")
    except Exception as e:
        st.error(f"Error creating CSV for download: {e}")
        return b""

if not filtered.empty:
    st.markdown("---")
    st.download_button(
        "‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏≠‡∏á‡πÅ‡∏•‡πâ‡∏ß (CSV)",
        data=_to_csv_bytes(filtered),
        file_name="filtered_result.csv",
        mime="text/csv"
    )
